<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenNebula</title>
    <link>https://opennebula.github.io/website/</link>
    <description>Recent content on OpenNebula</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="https://opennebula.github.io/website/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ansible Playbooks</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/playbooks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/playbooks/</guid>
      <description>Newly provisioned physical resources are mostly running only a base operating system without any additional services. Hosts need to pass the configuration phase to setup the additional software repositories, install packages, and configure and run necessary services to comply with the intended host purpose. This configuration process is fully handled by the oneprovision tool as part of the initial deployment (oneprovision create) or independent run anytime later (oneprovision configure).</description>
    </item>
    <item>
      <title>Cloud Architecture Design</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/cloud_architecture_and_design/cloud_architecture_design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/cloud_architecture_and_design/cloud_architecture_design/</guid>
      <description>This page describes the high-level steps to design and deploy an OpenNebula cloud.&#xA;To familiarize yourself with deployment and daily operations, or if you want to quickly try an Edge, Hybrid or Multi-cloud deployment, we strongly recommend you begin with the Quick Start Guide. In the Quick Start, you can:&#xA;Install an OpenNebula Front-end Deploy on-demand Edge Clusters on remote cloud providers Deploy Virtual Machines and Kubernetes clusters As you follow the tutorials you will learn the basic usage and operation of your cloud.</description>
    </item>
    <item>
      <title>Contextualization</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/kvm_contextualization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/kvm_contextualization/</guid>
      <description>OpenNebula provides a set of contextualization packages for different operating systems that integrates the VM guests with the OpenNebula services. The OpenNebula contextualization process allows to automatically:&#xA;Configure guest networking and hostname settings. Set up user credentials for seamless VM access. Define the system timezone. Resize disk partitions as needed. Execute custom actions during boot. All the OS appliances available in the OpenNebula Marketplace comes with all the software pre-installed.</description>
    </item>
    <item>
      <title>Create an Emulated Environment with miniONE</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_learning_environment/create_an_emulated_environment_with_minione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_learning_environment/create_an_emulated_environment_with_minione/</guid>
      <description>Placeholder text for Create an Emulated Env.</description>
    </item>
    <item>
      <title>Download</title>
      <link>https://opennebula.github.io/website/docs/releases/downloads/download/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/downloads/download/</guid>
      <description>Placeholder text for page that needs to be written, title not definitive.</description>
    </item>
    <item>
      <title>Extensions in Integration Section</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/extensions/extensions_in_integration_section/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/extensions/extensions_in_integration_section/</guid>
      <description>Placeholder page for page(s) in this section, number and titles undefined yet.</description>
    </item>
    <item>
      <title>Extensions in Provider Section</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/providers/extensions_in_provider_section/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/providers/extensions_in_provider_section/</guid>
      <description>Placeholder page for page(s) in this section, number and titles undefined yet.</description>
    </item>
    <item>
      <title>How To Create An Appliance</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/appliances/how_to_create_an_appliance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/appliances/how_to_create_an_appliance/</guid>
      <description>Placeholder text for page to be written.</description>
    </item>
    <item>
      <title>Install</title>
      <link>https://opennebula.github.io/website/docs/ai_operations/installation_and_configuration/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/ai_operations/installation_and_configuration/install/</guid>
      <description>Placeholder text for page that needs to be written, document title not definitive.</description>
    </item>
    <item>
      <title>Managed Kubernetes Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/managed_kubernetes/managed_kubernetes_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/managed_kubernetes/managed_kubernetes_overview/</guid>
      <description>Placeholder page for the ToC, page not yet written - 05 Feb.</description>
    </item>
    <item>
      <title>Marketplaces in Sunstone</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/managing_marketplaces_in_sunstone/sunstone_marketplaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/managing_marketplaces_in_sunstone/sunstone_marketplaces/</guid>
      <description>The Sunstone web UI allows you to graphically manage marketplaces. Within Sunstone, open the left-hand pane, then select Storage -&amp;gt; Marketplaces to perform the following operations:&#xA;Create a marketplace Update a marketplace Delete a marketplace Enable or disable a marketplace Change the owner or the group of a marketplace Check details of a marketplace See the appliances that have a marketplace Note Only OpenNebula Systems, LinuxContainers, HTTP and S3 marketplaces could be created with Sunstone.</description>
    </item>
    <item>
      <title>Metrics Predictions</title>
      <link>https://opennebula.github.io/website/docs/ai_operations/ai-driven_metrics_predictions/metrics_predictions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/ai_operations/ai-driven_metrics_predictions/metrics_predictions/</guid>
      <description>Placeholder text for page that needs to be written, document title not definitive.</description>
    </item>
    <item>
      <title>Oneaiops Overview</title>
      <link>https://opennebula.github.io/website/docs/ai_operations/overview_of_oneaiops/oneaiops_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/ai_operations/overview_of_oneaiops/oneaiops_overview/</guid>
      <description>Placeholder text for page that needs to be written, document title not definitive.</description>
    </item>
    <item>
      <title>OpenNebula Enterprise and Community Editions</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/opennebula_enterprise_and_community_editions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/opennebula_enterprise_and_community_editions/</guid>
      <description>The Release Notes section now includes notes for CE and EE, so this would be a new page explaining the differences between the EE and CE editions, using the content from:&#xA;What is OpenNebula CE&#xA;What is OpenNebula EE</description>
    </item>
    <item>
      <title>OpenNebula Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/opennebula_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/opennebula_overview/</guid>
      <description>Welcome to OpenNebula, the open source Cloud &amp;amp; Edge Computing Platform bringing real freedom to your Enterprise Cloud 🚀&#xA;This page provides a high-level overview of the OpenNebula cloud model, architecture and components. To familiarize yourself with OpenNebula and build an evaluation environment, we strongly recommend you follow the tutorials in our Quick Start Guide. For a description of the steps needed to build a production environment, please refer to Cloud Architecture Design.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/overview/</guid>
      <description>The public OpenNebula Marketplace includes easy-to-use appliances, which are preconfigured Virtual Machines that can be used to deploy different services. These appliance include the images with all necessary packages installed for the service run, including the OpenNebula contextualization packages and specific scripts that bring the service up on boot. This allows to customize the final service state by the cloud user via special contextualization parameters.&#xA;No security credentials are persisted in the distributed appliances.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/private_marketplaces/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/private_marketplaces/overview/</guid>
      <description>Besides the public Marketplaces (leveraging various remote public repositories with existing Appliances and accessible universally by all OpenNebula instances), the private ones allow the cloud administrators to create the private Marketplaces within an single organization in a specific OpenNebula (single zone) or shared by a Federation (collection of zones). Private Marketplaces provide their users with an easy way of privately publishing, downloading and sharing their own custom Appliances.&#xA;A Marketplace is a repository of Marketplace Appliances.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/public_marketplaces/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/public_marketplaces/overview/</guid>
      <description>OpenNebula will configure by default the following Marketplaces in your installation:&#xA;Marketplace Name Description OpenNebula Public The official public OpenNebula Systems Marketplace Linux Containers The public LXC image repository Important The OpenNebula front-end needs access to the Internet to use the public Marketplaces. Only the OpenNebula Public marketplace is enabled by default. Other marketplaces are initialized as disabled. To enable them use onemarket enable &amp;lt;market_id&amp;gt;.&#xA;You can list the marketplaces configured in OpenNebula with onemarket list.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/automatic_deployment_of_opennebula_with_one_deploy/one_deploy_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/automatic_deployment_of_opennebula_with_one_deploy/one_deploy_overview/</guid>
      <description>OpenNebula provides OneDeploy, a set of Ansible playbooks that allows you to automatically deploy an OpenNebula cloud in a simple and convenient way.&#xA;Ansible is a Python application for IT automation. It can deploy software, configure systems, and orchestrate complex deployments and workflows.&#xA;The Ansible playbooks in OneDeploy install a complete OpenNebula cloud, including the Front-end with the OneFlow and OneGate services, and the Sunstone UI. Before running the playbooks, you can modify variables to configure the OpenNebula cloud that will be created.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/overview/</guid>
      <description>Note Note for docs migration: need to modify text in this page, as in all “Overview” pages. So we heard you want to try out OpenNebula? Welcome! You came to the right place.&#xA;The pages in this section will help you through the process of achieving a fully functional OpenNebula cloud, through a series of tutorials that will take you from a bare install to quickly deploying an enterprise-grade Kubernetes cluster.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/overview/</guid>
      <description>This chapter contains documentation on how to create and manage Virtual Machines Backups. Backups are managed through the datastore and image abstractions. In this way, all the concepts that apply to these objects also apply to backups like access control or quotas. Backup datastores can be defined using two backends (datastore drivers):&#xA;restic, based on the restic backup tool rsync, that uses the rsync utility to transfer backup files. How Should I Read This Chapter Before reading this chapter, you should have already installed your Frontend, the KVM Hosts and have an OpenNebula cloud up and running with at least one virtualization node.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/overview/</guid>
      <description>A Host is a server that has the ability to run Virtual Machines and that is connected to OpenNebula’s Front-end server. To learn how to prepare the Hosts, you can read the Open Cluster Deployment guide. Hosts are usually grouped in Clusters.&#xA;How Should I Read This Chapter In this chapter there are four guides describing these objects.&#xA;Host Management: Host management is achieved through the onehost CLI command or through the Sunstone GUI.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/overview/</guid>
      <description>When a new Virtual Machine is launched, OpenNebula will connect its virtual network interfaces (defined by NIC attributes) to hypervisor network link devices as defined in the corresponding Virtual Network. This will allow the VM to have access to public and private networks.&#xA;OpenNebula supports the following networking modes:&#xA;Bridged. The VM NIC is added to a Linux bridge on the Host. This mode can be configured to use Security Groups and network isolation.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/overview/</guid>
      <description>Datastore Types Storage in OpenNebula is designed around the concept of Datastores. A Datastore is any storage medium to store disk images. OpenNebula distinguishes between three different Datastore types:&#xA;Images Datastore, which stores the base operating system images, persistent data volumes, CD-ROMs. System Datastore holds disks of running Virtual Machines. Disk are moved from/to the Images when the VMs are deployed/terminated. Files &amp;amp; Kernels Datastore to store plain files (not disk images), e.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/overview/</guid>
      <description>OpenNebula comes with a default internal user authentication system based on username/password, where information and secrets are stored in the OpenNebula (see the Users &amp;amp; Groups Subsystem guide). Dedicated external user authentication drivers can be used to leverage additional authentication mechanisms or sources of information about the users (e.g., LDAP). This chapter describes the available user authentication and management options.&#xA;Authentication In this figure you can see three authentication configurations you can customize in OpenNebula.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/capacity_planning/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/capacity_planning/overview/</guid>
      <description>How Should I Read This Chapter This Chapter shows different mechanism available to administrators to control the capacity assigned to Virtual Machines as well as that available to the users:&#xA;First you can control the apparent capacity of Hosts configuring its overcommitment. Also you can fine tune the scheduling policies that controls how resources from Hosts, Datastores, and Virtual Networks are allocated to Virtual Machines. Similarly, you can limit the resources that are made available to users with the quota system.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/overview/</guid>
      <description>This chapter contains documentation on how to configure OpenNebula to work with Prometheus monitoring and alerting toolkit. The integration consists of four components:&#xA;A Libvirt Exporter, that provides information about VM (KVM domains) running on an OpenNebula host. An OpenNebula Exporter, that provides basic information about the overall OpenNebula cloud. Alert rules sample files based on the provided metrics Grafana dashboards to visualize VM, Host and OpenNebula information in a convenient way.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/auth_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/auth_overview/</guid>
      <description>OpenNebula includes a complete user &amp;amp; group management system.&#xA;The resources a user may access in OpenNebula are controlled by a permissions system that resembles the typical UNIX one. By default, only the owner of a resource can use and manage it. Users can easily share the resources by granting use or manage permissions to other users in her group or to any other user in the system.&#xA;Upon group creation, an associated administrator user can be created.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/overview/</guid>
      <description>How Should I Read This Chapter This Chapter shows different mechanism available to administrators to control the capacity assigned to Virtual Machines as well as that available to the users:&#xA;First you can control the apparent capacity of Hosts configuring its overcommitment. Also you can fine tune the scheduling policies that controls how resources from Hosts, Datastores, and Virtual Networks are allocated to Virtual Machines. Similarly, you can limit the resources that are made available to users with the quota system.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/overview/</guid>
      <description>WHMCS is a web host billing automation platform which can be configured for many uses. We provide a Module for WHMCS which allows you to automate the creation and management of Users, Groups, and their Access Control Lists inside of OpenNebula, as well as provide billing based on their usage metrics.&#xA;You will be able to define these resource packages to control the usage and cost of your OpenNebula resources.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/data_center_federation/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/data_center_federation/overview/</guid>
      <description>The OpenNebula Federation is a tightly coupled integration of several instances of OpenNebula Front-end (called Zones), where each instance (Zone) shares the same user accounts, groups, and permissions configuration. You can define access policies federation-wide where users can be restricted to certain Zones, or to specific Clusters inside a Zone. Federation topology consists of one master and several slave Front-ends (any other federation configurations, e.g. deeper master-slave hierarchy, aren’t supported).</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/overview/</guid>
      <description>This chapter contains reference guides for Sunstone end-users.&#xA;How Should I Read This Chapter The following sections are intended for the cloud consumers. They can skip most of the OpenNebula documentation and read these two guides only.&#xA;Proceed to the corresponding guide following these links:&#xA;Self-service Cloud View: For cloud consumers that just require a portal where they can provision new virtual machines and services easily. Group Admin View: For group administrators.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/high_availability/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/high_availability/overview/</guid>
      <description>No host or service is absolutely reliable; we experience failures across various areas every day. To avoid the down-time and the consequent damages, we try to avoid a single point of failure by running several instances of the same service. Failure of one instance doesn’t mean complete service unavailability, as there are other instances that can handle the workload. Such deployment is highly available and resilient to partial failure.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/overview/</guid>
      <description>This chapter describes the performance capabilities of various OpenNebula components and how to deploy and configure OpenNebula on a large scale or just fine-tune the performance.&#xA;How Should I Read This Chapter Read the Scalability Testing and Tuning to understand the performance capabilities of OpenNebula and ways to improve performance by following test scenarios. Move on to the Sunstone for Large Deployment to learn how to achieve a better performance and security by running Sunstone GUI within a web server or behind HTTP(S) proxy.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/overview/</guid>
      <description>This chapter is a configuration and deployment reference for all OpenNebula services. It contains the description of the configuration files (for least effort, basic and even advanced setups), how to stop and start them, and where to find their logs.&#xA;How Should I Read This Chapter Read the sections for services you are interested in&#xA;OpenNebula Daemon Scheduler Monitoring FireEdge OneFlow OneGate Move on to Database Maintenance and Troubleshooting.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/overview/</guid>
      <description>The Front-end is the central part of an OpenNebula installation and is the very first thing that needs to be deployed (or upgraded). Typically it’s a host where the OpenNebula server-side components are installed and which is responsible for the management of an entire virtualization stack. It can be a physical host or a virtual machine (this decision is left up to the cloud administrator) as long as it matches the requirements.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/kvm_node_deployment/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/kvm_node_deployment/overview/</guid>
      <description>KVM (Kernel-based Virtual Machine) is the main virtualization solution for Linux on x86 hardware that contains virtualization extensions (Intel VT or AMD-V). It consists of the loadable KVM kernel modules (one that provides the core virtualization infrastructure and several processor-specific modules), but the complete KVM virtualization stack usually also contains the user-space machine hardware emulator QEMU accelerated by the KVM and virtual machines management tool libvirt.&#xA;By using KVM, you can run multiple Virtual Machines with unmodified Linux or Windows images.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/lxc_node_deployment/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/lxc_node_deployment/overview/</guid>
      <description>LXC is a Linux technology which allows us to create and manage system and application containers. The containers are computing environments running on a particular hypervisor Node alongside other containers or Host services, but secured and isolated in their own namespaces (user, process, network).&#xA;From the perspective of a hypervisor Node, such a container environment is just an additional process tree among other hypervisor processes. Inside of the environment, it looks like a standard Linux installation that sees only its own resources but shares the host kernel.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/overview/</guid>
      <description>How Should I Read This Chapter Some applications require multiple VMs to implement their workflow. OpenNebula allows you to coordinate the deployment and resource usage of such applications through the OneFlow component.&#xA;This component is able to deploy services, these services are a group of interconnected virtual machines that work as an entity. They can communicate each other using virtual networks deployed by the OneFlow server itself and they can also have some relationship.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_backups/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_backups/overview/</guid>
      <description>Placeholder page - write brief overview based on operations.rst and cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/overview.rst (vm_backups_overview).</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_images/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_images/overview/</guid>
      <description>How Should I Read This Chapter In OpenNenbula there are two main places where VM disk images are stored:&#xA;Marketplaces, these are shared locations across multiple OpenNebula clouds. They can be public or for private use. Marketplaces store Marketplace Applications (or Appliances), that includes the application definition together with the disk images. Datastores, these are the local storage areas of a cloud. They typically refer to storage clusters or hypervisor disks and are mainly devoted to store disk images.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/overview/</guid>
      <description>This chapter contains documentation on how to create and manage Virtual Networks and their related objects&#xA;How Should I Read This Chapter Before reading this chapter, you should have already installed and configured your cloud. The Chapter is structured as follows:&#xA;The Virtual Networks and Virtual Networks Templates explain how to create networks. The Self Provision section details how regular users can self-provision virtual networks for their use. You will also find information on Security Groups, to easily define firewall rules.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/overview/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/overview/</guid>
      <description>A Provider represents a Cloud where resources (hosts, networks or storage) are allocated to implement a Provision. Usually a Provider includes a zone or region in the target Cloud and an account that will be used to create the resources needed.&#xA;How Should I Read This Chapter In this chapter you can find a guide on how to create Providers based on the supported Clouds. The following Cloud providers are enabled by default after installing OpenNebula:</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/overview/</guid>
      <description>Edge Clusters provide you with the tools needed to dynamically grow your cloud infrastructure with physical or virtual resources running on remote cloud providers. Edge Clusters support two main use cases:&#xA;Edge Cloud Computing, to transition from centralized clouds to distributed edge-like cloud environments. You will be able to grow your on-premises cloud with resources at edge data center locations to meet the latency, bandwidth or data regulation needs of your workload.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/hci_cluster_provisions/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/hci_cluster_provisions/overview/</guid>
      <description>HCI Clusters features an hyperconvergent storage configuration based on Ceph. Compared to the Edge Cluster, HCI provides a high available solution. The HCI Clusters are based on bare-metal servers and support the LXC and KVM hypervisors.&#xA;How Should I Read This Chapter In this chapter you can find a guide on how to automatically deploy HCI Clusters on bare-metal on:&#xA;Amazon AWS Edge Clusters On-Premise Edge Cluster Hypervisor Compatibility HCI Clusters are compatible with the KVM and LXC hypervisors.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_operations/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_operations/overview/</guid>
      <description>How Should I Read This Chapter Provisions in the form of Edge Clusters or HCI Clusters provide you with the tools needed to dynamically grow your cloud infrastructure on remote cloud providers or on-premises resources. In this chapter you can find a guide on how to:&#xA;Operate your edge or HCI clusters Manage Cloud or on-premises providers. Hypervisor Compatibility Provisions are compatible with the KVM and LXC hypervisors.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/overview/</guid>
      <description>How Should I Read This Chapter You should be reading this Chapter if you are trying to build OpenNebula from source code or trying to extend the Sunstone functionality.&#xA;This Chapter covers what are the OpenNebula software dependencies, how to compile OpenNebula and how to extend Sunstone functionality.&#xA;Hypervisor Compatibility All the Sections of this Chapter applies to all hypervisors.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/edge_provider_driver_development/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/edge_provider_driver_development/overview/</guid>
      <description>How Should I Read This Chapter These guides shows you how to create new providers to OpenNebula Edge Clusters component. It is intended for Cloud developers that need to create Edge Cluster on a provider not supported in the official distribution.&#xA;Hypervisor Compatibility These guides are compatible with all hypervisors.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/overview/</guid>
      <description>The interactions between OpenNebula and the Cloud infrastructure are performed by specific drivers. Each one addresses a particular area:&#xA;Storage. The OpenNebula core issue abstracts storage operations (e.g. clone or delete) that are implemented by specific programs that can be replaced or modified to interface special storage backends and file-systems. Virtualization. The interaction with the hypervisors are also implemented with custom programs to boot, stop or migrate a virtual machine.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/overview/</guid>
      <description>OpenNebula has been designed to be easily adapted to any infrastructure and easily extended with new components. The result is a modular system that can implement a variety of Cloud architectures and can interface with multiple datacenter services. In this Guide we review the main interfaces of OpenNebula and their.&#xA;How Should I Read This Chapter You should be reading this Chapter if you are trying to automate tasks in your deployed OpenNebula cloud, and you have already read all of the previous guides.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/overview/</guid>
      <description>Important Complete feature is available in OpenNebula Enterprise Edition. Only a single functionality comes in Community Edition.&#xA;OpenNebula has tens of configuration files, where cloud administrators can fine-tune the behavior of their cloud environment. When doing an upgrade to a newer minor OpenNebula version (X.Y), unfortunately, all custom changes in configuration files must be migrated to new configuration files. OpenNebula Enterprise Edition comes with a dedicated tool (onecfg), which automates and simplifies the upgrade of configuration files.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/overview/</guid>
      <description>Keeping your OpenNebula up-to-date is very important, as you will receive the latest functionality and, more importantly, the latest security patches. It is possible to upgrade to the latest OpenNebula release from earlier versions.&#xA;If you are using the Enterprise Edition you can upgrade from previous OpenNebula versions. If you are using the Community Edition you can only upgrade from the previous stable release if you are using your cloud for non-commercial purposes and you need to request the migrator package.</description>
    </item>
    <item>
      <title>Overview</title>
      <link>https://opennebula.github.io/website/docs/tools/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/tools/overview/</guid>
      <description>&#xA;OpenNebula includes a number of extensions and plug-ins that allows the integration of OpenNebula with other open source software. In this guide we review the integration of OpenNebula with following third party tools:&#xA;Ansible: to manage common OpenNebula resources, e.g. VMs, images or hosts, using Ansible playbooks Terraform: to create and manage OpenNebula clusters resources (e.g VMs, images, services, …) using the OpenNebula Terraform Provider </description>
    </item>
    <item>
      <title>Predictive Scheduling</title>
      <link>https://opennebula.github.io/website/docs/ai_operations/smart_scheduling_of_virtual_machines/predictive_scheduling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/ai_operations/smart_scheduling_of_virtual_machines/predictive_scheduling/</guid>
      <description>Placeholder text for page that needs to be written, title not definitive.</description>
    </item>
    <item>
      <title>Virtual Machine Instances</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_instances/vm_instances/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_instances/vm_instances/</guid>
      <description>This guide follows the Creating Virtual Machines guide. Once a Template is instantiated to a Virtual Machine, there are a number of operations that can be performed using the onevm command.&#xA;Virtual Machine States The life-cycle of a Virtual Machine within OpenNebula includes the following stages:&#xA;Note Note that this is a simplified version. If you are a developer you may want to take a look at the complete diagram referenced in the Virtual Machines States Reference guide): Short state State Meaning pend Pending By default a VM starts in the pending state, waiting for a resource to run on.</description>
    </item>
    <item>
      <title>Virtual Machine Template</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/template/</guid>
      <description>A template file consists of a set of attributes that defines a Virtual Machine. Using the command onetemplate create, a template can be registered in OpenNebula to be instantiated later. For compatibility with previous versions, you can also create a new Virtual Machine directly from a template file, using the onevm create command.&#xA;Warning Some template attributes can compromise the security of the system or the security of other VMs, and can be used only by users in the oneadmin group.</description>
    </item>
    <item>
      <title>Ansible Roles</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/roles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/roles/</guid>
      <description>Warning This chapter is only for advanced users who need to modify the host configuration process significantly. Unless the configuration process doesn’t meet your requirements, you don’t need to be familiar with this part. The following roles are shipped with the OpenNebula provision tool and installed into /usr/share/one/oneprovision/ansible/roles/.&#xA;Role ceph-opennebula-facts This role is used to make ceph_oneadmin_key and ceph_oneadmin_keyring facts accessible for used on ceph-opennebula-osd&#xA;No parameters.&#xA;Role ceph-opennebula-mon Creates OpenNebula Ceph pools</description>
    </item>
    <item>
      <title>Automated Deploy and Configuration</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deploy and Configuration</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deploy and Configuration</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>AWS Edge Cluster</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/aws_cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/aws_cluster/</guid>
      <description>Edge Cluster Types The AWS metal edge clusters uses baremetal instances to create OpenNebula Hosts, providing the best performance and highest capacity. These edge clusters can run LXC or KVM hypervisors.&#xA;AWS Edge Cluster Implementation An Edge Cluster in AWS creates the following resources:&#xA;AWS instance: Host to run virtual machines. AWS VPC: it creates an isolated virtual network for all the deployed resources. There are some limits in the number of VPC that can be requested by the user, please refer to this link for more information.</description>
    </item>
    <item>
      <title>AWS HCI Cluster</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/hci_cluster_provisions/aws_cluster_ceph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/hci_cluster_provisions/aws_cluster_ceph/</guid>
      <description>AWS HCI Cluster Implementation HCI Cluster Nodes The HCI cluster consists of three different type of servers:&#xA;Full nodes, run Ceph OSD and Monitor daemons as well as the selected hypervisor. In order to get a fault tolerant cluster a number of 3 nodes of this type is recommended. OSD nodes, run Ceph OSD daemon and the selected hypervisor. Hypervisor-only nodes, run the selected hypervisor and the Ceph client tools.</description>
    </item>
    <item>
      <title>AWS Provider</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/aws_provider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/aws_provider/</guid>
      <description>An AWS provider contains the credentials to interact with Amazon and also the region to deploy your Provisions. OpenNebula comes with four pre-defined AWS providers in the following regions:&#xA;Frankfurt London North Virginia (US) North California (US) In order to define an AWS provider, you need the following information:&#xA;Credentials: these are used to interact with the remote provider. You need to provide access_key and secret_key. You can follow this guide.</description>
    </item>
    <item>
      <title>Backup Datastore: Restic</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/restic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/restic/</guid>
      <description>Restic is an open source (BSD 2-Clause License) backup tool designed for speed, security and efficiency. The current implementation of the driver uses the SFTP storage type. Restic offers interesting features to store backups, like deduplication (only transferring image blobs not already present in the repository) or compression (enabled by default).&#xA;In both the Enterprise and Community editions of OpenNebula, the correct version of restic is included as a dependency.</description>
    </item>
    <item>
      <title>Basic Usage</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/usage/</guid>
      <description>This section covers onecfg tool subcommands:&#xA;status - Versions status init - Initialize version management state validate - Validate current configuration files diff - Identify changes in configuration files patch - Apply ad-hoc changes (from diff) in configuration files upgrade - Upgrade configuration files to a new version Important This command must be always run under privileged user root directly or via sudo. For example:&#xA;$ sudo onecfg status The tool comes with help for each subcommand and command-line option.</description>
    </item>
    <item>
      <title>Building from Source Code</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/compile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/compile/</guid>
      <description>This page will show you how to compile and install OpenNebula from the sources.&#xA;Warning Do not forget to check the Building Dependencies for a list of specific software requirements to build OpenNebula. Note If you need to build customized OpenNebula packages you can find the source packages for publicly released versions available in the download repositories for easy rebuilds and customizations. If you need to access the packaging tools, please expose your case to &amp;lt;community-manager@opennebula.</description>
    </item>
    <item>
      <title>Cloud Deployment - Local Storage</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/automatic_deployment_of_opennebula_with_one_deploy/one_deploy_tutorial_local_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/automatic_deployment_of_opennebula_with_one_deploy/one_deploy_tutorial_local_ds/</guid>
      <description>Overview In this tutorial, we’ll use OneDeploy to automatically deploy a simple OpenNebula cloud, with one Front-end and two Hosts using local storage. In this configuration the virtual disk images are transferred from the Front-end to the Hypervisors’ local storage using the SSH protocol.&#xA;This sample architecture uses a basic network configuration, a flat (bridged) network, where each VM’s IP is part of the same network as the Hypervisors.</description>
    </item>
    <item>
      <title>Creating Disk Images</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/creating_images/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/creating_images/</guid>
      <description>When it comes to creating OS disk images for your VM guests, you have several options:&#xA;OpenNebula Marketplace Appliances: Utilize ready-to-use OpenNebula Marketplace appliances. OpenNebula Apps Project: Build or customize your own images using the build toolchain provided by the OpenNebula Apps project. Manual Installation: Perform a manual installation directly in a running VM guest. OpenNebula Marketplace Appliances If you have access to the public OpenNebula Marketplace from your frontend, you’ll find pre-configured images ready to run in an OpenNebula Cloud.</description>
    </item>
    <item>
      <title>Database Setup</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/database/</guid>
      <description>OpenNebula Front-end uses the database to persist the complete state of the cloud. It supports several database solutions and each is recommended for different usage. It’s necessary to decide carefully which solution is the best for your needs, as the migration of an existing installation to a different database type is complex or impossible (depending on the Back-end). The following options are available:&#xA;default embedded SQLite for small workloads, recommended MySQL/MariaDB for production, It’s recommended to install the database Back-end now.</description>
    </item>
    <item>
      <title>Datastores</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/datastores/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/datastores/</guid>
      <description>Types OpenNebula features three different datastore types:&#xA;The Image Datastore, stores the Image repository. The System Datastore holds disk for running virtual machines, usually cloned from the Image Datastore. The Files &amp;amp; Kernels Datastore to store plain files used in contextualization, or VM kernels used by some hypervisors. By default, OpenNebula will create an image (default), system (system), and files datastore (files). These datastores are configured to use the SSH protocol to transfer images.</description>
    </item>
    <item>
      <title>Defining and Managing Virtual Networks</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/manage_vnets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/manage_vnets/</guid>
      <description>Commonly a Host is connected to one or more networks that are available to the VMs through bridges. OpenNebula allows the creation of Virtual Networks by mapping them on top of the physical ones.&#xA;Virtual Network Definition A Virtual Network definition consists of three different parts:&#xA;The underlying physical network infrastructure that will support it, including the network driver. The logical address space available. Addresses associated to a Virtual Network can be IPv4, IPv6, dual stack IPv4-IPv6 or Ethernet.</description>
    </item>
    <item>
      <title>Edge Cloud Reference Architecture</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/cloud_architecture_and_design/edge_cloud_reference_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/cloud_architecture_and_design/edge_cloud_reference_architecture/</guid>
      <description>To support digital transformation initiatives, IT departments need the right blend of on-premises, public and edge cloud environments to support a variety of existing and emerging use cases while avoiding vendor lock-in and enabling cost optimization. They also need to combine virtual machine workloads with containerized applications from Kubernetes in a shared environment to get the best of both worlds: mature virtualization technologies and orchestration of application containers.&#xA;This document presents a powerful distributed Edge Cloud Architecture for OpenNebula composed of Edge Clusters that can run any workload - both virtual machines and containerized applications — on any resource — bare metal or virtualized — anywhere on premises and on a cloud provider.</description>
    </item>
    <item>
      <title>Federation Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/data_center_federation/config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/data_center_federation/config/</guid>
      <description>This section will explain how to configure two (or more) OpenNebula Zones to work as federation master and slave. The process described here can be applied to new installations or existing OpenNebula instances.&#xA;OpenNebula master Zone server replicates database changes on slaves using a federated log. The log contains the SQL commands which should be applied in all Zones.&#xA;In this document, each configuration step starts with Master or Slave to indicate the server where the step must be performed.</description>
    </item>
    <item>
      <title>Frontend HA</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/high_availability/frontend_ha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/high_availability/frontend_ha/</guid>
      <description>OpenNebula provides a built-in mechanism to ensure high availability (HA) of the core Front-end services - opennebula (i.e., daemon oned) and opennebula-scheduler (i.e., daemon mm_sched). Services need to be deployed and configured across several hosts and a distributed consensus protocol to provide fault-tolerance and state consistency across them. Such deployment is resilient to the failure of at least a single host (it depends on the total number of hosts).</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Host Overcommitment</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/capacity_planning/overcommitment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/capacity_planning/overcommitment/</guid>
      <description>Before allocating a VM to a Host, the Scheduler checks that the capacity requested by the VM fits in the available capacity of the Host. The overall number of VMs assigned to a Host can be controlled by:&#xA;Adjusting the total capacity announced by each Host. Adjusting the capacity requested by the VM. Virtual Machine Capacity The resource allocation of the VM is expressed with the following attributes:&#xA;CPU, percentage of CPU divided by 100 required for the VM, e.</description>
    </item>
    <item>
      <title>Hosts</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/hosts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/hosts/</guid>
      <description>In order to use your existing physical nodes, you have to add them to OpenNebula as Hosts. To add a Host only its hostname and type is needed.&#xA;Warning Before adding a Linux Host check that you can SSH to it without being prompted for a password. Creating and Deleting Hosts Hosts are the servers managed by OpenNebula responsible for running VMs. To use these Hosts in OpenNebula you need to register them so they are monitored and made available to the scheduler.</description>
    </item>
    <item>
      <title>How To Certify An Appliance</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/appliances/how_to_certify_an_appliance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/appliances/how_to_certify_an_appliance/</guid>
      <description>Placeholder text for page to be written.</description>
    </item>
    <item>
      <title>HTTP Marketplace</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/private_marketplaces/market_http/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/private_marketplaces/market_http/</guid>
      <description>Overview This Marketplace uses a conventional HTTP server to expose the images (Marketplace Appliances) uploaded to the Marketplace. The image will be placed in a specific directory (available on or at least accessible from the Front-end), that must be also served by a dedicated HTTP service.&#xA;This is a fully supported Marketplace with all the implemented features.&#xA;Requirements The web server should be deployed either in the Front-end or on a node reachable by the Front-end.</description>
    </item>
    <item>
      <title>Image Template</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/img_template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/img_template/</guid>
      <description>This page describes how to define a new image template. An image template follows the same syntax as the VM template.&#xA;Warning Some template attributes can compromise the security of the system or the security of other VMs, and can be used only by users in the oneadmin group. These attributes can be configured in oned.conf. In the following tables, default attributes are marked with *. For the complete list, see the Restricted Attributes section.</description>
    </item>
    <item>
      <title>Images</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_images/images/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_images/images/</guid>
      <description>An OpenNebula Image represents a VM disk. Images can have multiple formats (e.g. filesystem or block device) and can store OS installations, data filesystems, images or kernels. In this guide you’ll learn about different Image types, and how to mange and use them.&#xA;Types and Persistency OpenNebula uses three different Image types to represent VM disks. A VM can use multiple Image types simultaneously:&#xA;Operating System (OS): Main disk, the VM will start from this Image.</description>
    </item>
    <item>
      <title>Installation and Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/install/</guid>
      <description>This page describes how to install the OpenNebula Prometheus integration packages available in the OpenNebula software repositories.&#xA;Step 1. OpenNebula Repositories [Front-end, Hosts] At this point OpenNebula software repositories should already be configured in your front-end and hosts. Double check this is the case before proceeding, more information can be found in the OpenNebula Repositories guide.&#xA;Step 2. Install Front-end Packages [Front-end] In your OpenNebula front-end, install the Prometheus package.</description>
    </item>
    <item>
      <title>Key Features</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/key_features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/key_features/</guid>
      <description>OpenNebula offers a simple but feature-rich and flexible solution to build and manage data center virtualization and enterprise clouds. This page provides a summary of its key features(*).&#xA;To learn more about the infrastructure platforms and services supported in each version of OpenNebula, refer to the Platform Notes for each version.&#xA;For high-level overviews and in-depth technical guides, please refer to OpenNebula’s White Papers.&#xA;INTERFACES&#xA;Simple, clean, intuitive GUI, with different views for cloud admins and end users Powerful command-line tools resembling typical Unix tools API in multiple languages APPLICATION MANAGEMENT AND CATALOG</description>
    </item>
    <item>
      <title>KVM Node Installation</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/kvm_node_deployment/kvm_node_installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/kvm_node_deployment/kvm_node_installation/</guid>
      <description>This page shows you how to configure OpenNebula KVM Node from the binary packages.&#xA;Note Before reading this chapter, you should have at least installed your Front-end node. Step 1. Add OpenNebula Repositories Refer to OpenNebula Repositories guide to add the Enterprise and Community Edition software repositories.&#xA;Step 2. Installing the Software Installing on CentOS/RHEL Repository EPEL OpenNebula depends on packages which aren’t in the base distribution repositories. Execute one of the commands below (distinguished by the host platform) to configure access to additional EPEL (Extra Packages for Enterprise Linux) repository:</description>
    </item>
    <item>
      <title>LXC Node Installation</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/lxc_node_deployment/lxc_node_installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/lxc_node_deployment/lxc_node_installation/</guid>
      <description>This page shows you how to configure OpenNebula LXC Node from the binary packages.&#xA;Note Before reading this chapter, you should have at least installed your Front-end node. Step 1. Add OpenNebula Repositories Refer to OpenNebula Repositories guide to add the Enterprise and Community Edition software repositories.&#xA;Step 2. Installing the Software Installing on AlmaLinux/RHEL Repository EPEL OpenNebula depends on packages which aren’t in the base distribution repositories. Execute one of the commands below (distinguished by the host platform) to configure access to additional EPEL (Extra Packages for Enterprise Linux) repository:</description>
    </item>
    <item>
      <title>Managed Kubernetes Description</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/managed_kubernetes/managed_kubernetes_description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/managed_kubernetes/managed_kubernetes_description/</guid>
      <description>Placeholder page for the ToC, page not yet written - 05 Feb.</description>
    </item>
    <item>
      <title>Managing Marketplace Appliances</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/marketapps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/marketapps/</guid>
      <description>A Marketplace Appliance is a generic resource (an entry on the marketplaceapp pool) that can be of any of the following three different types:&#xA;Image, a single Image, optionally including a VM template. VM, a VM template referring to one or more images. Service, a multi-VM service composed of one or more templates associated with images. This guide introduces the process to create and manage Marketplace Appliances.&#xA;Exploring Marketplace Appliances You can list the Marketplace Appliances (apps) with onemartketapp list command.</description>
    </item>
    <item>
      <title>Managing Providers</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_operations/provider_operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_operations/provider_operations/</guid>
      <description>You can manage your Edge providers with the command oneprovider. This will allow you to register the provider in OpenNebula and use it. There are two ways of using it:&#xA;As part of an Edge Cluster definition. When you create the Edge Cluster the provider information will be used. You can set the provider when creating a new Edge Cluster with the command oneprovision create and the parameter --provider. This will override any provider in the Edge Cluster definition template.</description>
    </item>
    <item>
      <title>OneFlow Services Management</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/appflow_use_cli/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/appflow_use_cli/</guid>
      <description>OneFlow allows users and administrators to define, execute and manage multi-tiered applications, which we call Services, composed of interconnected Virtual Machines with deployment dependencies between them. Each group of Virtual Machines is deployed and managed as a single entity and is completely integrated with the advanced OpenNebula user and group management.&#xA;What Is a Service The following diagram represents a multi-tier application. Each node represents a Role, and its cardinality (the number of VMs that will be deployed).</description>
    </item>
    <item>
      <title>OpenNebula Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/oned/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/oned/</guid>
      <description>The OpenNebula Daemon (oned) is the core service of the cloud management platform. It manages the cluster nodes, virtual networks and storages, groups, users and their virtual machines, and provides the XML-RPC API to other services and end-users. The service is distributed as an operating system package opennebula with system service opennebula.&#xA;Configuration The OpenNebula Daemon configuration file can be found in /etc/one/oned.conf on the Front-end and can be customized with the following parameters:</description>
    </item>
    <item>
      <title>OpenNebula Systems Marketplace</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/public_marketplaces/opennebula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/public_marketplaces/opennebula/</guid>
      <description>&#xA;The OpenNebula Marketplace is a catalog of virtual appliances ready to run in OpenNebula environments available at http://marketplace.opennebula.io/appliance.&#xA;Requirements No additional requirements needed.&#xA;Configuration Attributes Attribute Description NAME The name of the Marketplace. Default: OpenNebula Public MARKET_MAD one. ENDPOINT The Marketplace endpoint URL </description>
    </item>
    <item>
      <title>Provision Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/edge_provider_driver_development/provision_driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/edge_provider_driver_development/provision_driver/</guid>
      <description>An Edge Cluster provider is responsible to interface with the Cloud or Edge provider to provision the Edge cluster resources including hosts, public IPs or any other abstraction required to support the cluster. Note that the specific artifacts needed depended on the features and capabilities of each provider.&#xA;Terraform Representation First you need to provide a representation of the Edge Cluster using Terraform. OpenNebula will use the Terraform driver for the target provider to provision the Edge Cluster infrastructure.</description>
    </item>
    <item>
      <title>Scalability Testing and Tuning</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/scalability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/scalability/</guid>
      <description>Determining the scalability of your cloud, and how to improve it, requires you to balance many variables. There are several aspects that can limit the scalability of a cloud, from the storage to the network Back-end, and no one solution meets everyone’s scalability goals. This guide firstly presents the scale limits of a single OpenNebula instance (single zone), and then provides some recommendations to tune your deployment for a larger scale.</description>
    </item>
    <item>
      <title>Scheduling Policies</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/scheduling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/scheduling/</guid>
      <description>The OpenNebula scheduler uses a Matchmaking algorithm to allocate VMs to Hosts. A matchmaking request consists of two parts:&#xA;Requirements, the target resource needs to fulfill these to be considered to allocate the VM. Resources that does not fulfill the requirements are filtered out. Rank, or preferences, a function that ranks the suitable resources to sort them. Resources with a higher rank are used first. OpenNebula uses this algorithm to schedule all resources types:</description>
    </item>
    <item>
      <title>Self-service Cloud View</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/cloud_view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/cloud_view/</guid>
      <description>This is a simplified view intended for cloud consumers that just require a portal where they can provision new VMs easily. To create new VMs and Services, they just have to select one of the available Templates prepared by the administrators.&#xA;Using the Cloud Create VM In this scenario the cloud administrator must prepare a set of Templates and Images to make them available to the cloud users. These resources must be ready to be used.</description>
    </item>
    <item>
      <title>SSH Authentication</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/ssh/</guid>
      <description>This guide will show you how to enable and use the SSH authentication with the OpenNebula CLI with authentication driver ssh. Using this method, users log in to the OpenNebula with a token encrypted with their private SSH keys.&#xA;Requirements No additional installation required.&#xA;Considerations &amp;amp; Limitations This authentication method works only for interaction with OpenNebula over CLI.&#xA;Configuration This authentication mechanism is enabled by default. If it doesn’t work, make sure you have the authentication method ssh enabled in the AUTH_MAD section of your /etc/one/oned.</description>
    </item>
    <item>
      <title>Start Here</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/start_here/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/start_here/</guid>
      <description>This guide describes the upgrade procedure for systems that are already running an OpenNebula Enterprise Edition 5.12.x or older. The upgrade to OpenNebula EE 7.0 can be done directly by following this section; you don’t need to perform intermediate version upgrades (for CE deployments, please see the Important Note below). The upgrade will preserve all current users, hosts, resources, and configurations, for both SQLite and MySQL/MariaDB back-ends.&#xA;Read the Compatibility Guide and Release Notes to know what’s new in OpenNebula 7.</description>
    </item>
    <item>
      <title>Terraform</title>
      <link>https://opennebula.github.io/website/docs/tools/terraform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/tools/terraform/</guid>
      <description>Terraform is used to create, manage, and manipulate infrastructure resources (e.g. physical machines, VMs, network switches, containers, etc.). Almost any infrastructure noun can be represented as a resource in Terraform. The OpenNebula provider is officially supported by HashiCorp and fully open source, the repository is available here.&#xA;The OpenNebula provider is used to interact with OpenNebula resources through Terraform. The provider allows you to manage your OpenNebula clusters resources. It needs to be configured with proper credentials before it can be used.</description>
    </item>
    <item>
      <title>Try OpenNebula Front-end On-prem</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/try_opennebula_onprem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/try_opennebula_onprem/</guid>
      <description>In this tutorial, we’ll install an OpenNebula Front-end in under ten minutes, using miniONE, the installation script provided by OpenNebula.&#xA;This simple installation includes a single OpenNebula Front-end without any hypervisor nodes. You can perform the installation on any physical or virtual server that meets the system requirements. Later, you can use this Front-end to provision resources on cloud providers, for example as described in Provisioning an Edge Cluster.</description>
    </item>
    <item>
      <title>Users</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/manage_users/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/manage_users/</guid>
      <description>OpenNebula supports user accounts and groups. This guide shows how to manage users, groups are explained in their own guide. To manage user rights, visit the Managing ACL Rules guide.&#xA;A user in OpenNebula is defined by a username and a password. You don’t need to create a new Unix account in the front-end for each OpenNebula user, they are completely different concepts. OpenNebula users are authenticated using a session string (with &amp;lt;user&amp;gt;:&amp;lt;password&amp;gt; format), this is included in every operation and validated by OpenNebula service.</description>
    </item>
    <item>
      <title>Virtual Network Templates</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/vn_templates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/vn_templates/</guid>
      <description>The Virtual Network Templates allows the end user to create virtual networks without knowing the details of the underlying infrastructure. Typically the administrator sets up the templates with the required physical attributes, e.g. driver or physical device information and let the end user to add all the logic information like address ranges or gateway.&#xA;Virtual Network Templates can be instantiated several times and shared between multiple users.&#xA;Virtual Network Template Definition A Virtual Network Template is a representation of a Virtual Network, so a template can be defined by using the same attributes available for a Virtual Network.</description>
    </item>
    <item>
      <title>Virtualization Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-vmm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-vmm/</guid>
      <description>The component that deals with the hypervisor to create, manage and get information about virtual machine objects is called Virtual Machine Manager (VMM for short). This component has two parts. The first one resides in the core and holds most of the general functionality common to all the drivers (and some specific), the second is the driver that is the one able to translate basic VMM actions to the hypervisor.</description>
    </item>
    <item>
      <title>VM Backup Operations</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_backups/operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_backups/operations/</guid>
      <description>Overview Backup Operations Backups can be operated in two modes:&#xA;Single VM (described in this guide). Backup operations are defined and managed for a single VM. You can use this method to manage the backups of few VMs. Backup Jobs are described in the backup jobs guide. They allow you to define backup operations involving multiple VMs and efficiently manage all the backups as a cohesive unit. Backup Types OpenNebula supports two backup types:</description>
    </item>
    <item>
      <title>What&#39;s New</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/whats_new/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/whats_new/</guid>
      <description>OpenNebula Core The ability to import wild VMs into OpenNebula has been removed from code to provide a more coherent management experience across all interfaces and APIs. The enforce parameter has been restored for the resize operation. In this context, it only manages capacity enforcement checks (memory and CPU), while the NUMA topology is always verified independently. Option to define Compute Quotas per Cluster to achieve more granular control of resources.</description>
    </item>
    <item>
      <title>WHMCS Install/Config</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/configure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/configure/</guid>
      <description>The install and update process are essentially identical. The Module files can be found in /usr/share/one/whmcs after you have installed the opennebula-whmcs-tenants package via your package manager. You will just need to merge the modules directory to the main WHMCS directory on the server hosting WHMCS. When updating the module just copy the files on top of the existing files and overwrite them. An example command for copying the files:</description>
    </item>
    <item>
      <title>XML-RPC API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/api/</guid>
      <description>This reference documentation describes the xml-rpc methods exposed by OpenNebula. Each description consists of the method name and the input and output values.&#xA;All xml-rpc responses share a common structure.&#xA;Type Data Type Description OUT Boolean True or false whenever is successful or not. OUT String If an error occurs this is the error message. OUT Int Error code. The output will always consist of three values. The first and third ones are fixed, but the second one will contain the String error message only in case of failure.</description>
    </item>
    <item>
      <title>Ansible</title>
      <link>https://opennebula.github.io/website/docs/tools/ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/tools/ansible/</guid>
      <description>OpenNebula Ansible modules allow managing common OpenNebula resources, e.g. VMs, images or hosts, using Ansible playbooks. In the latest Ansible version OpenNebula modules are part of the collection community.general. Formerly, they were distributed together with Ansible main package.&#xA;For the module usage, please follow the official Ansible documentation:&#xA;one_host.py one_image.py one_service.py one_vm.py one_template.py Dependencies For OpenNebula Ansible modules Python bindings PYONE are necessary, for one_image.py also legacy Python OCA</description>
    </item>
    <item>
      <title>Automated Deploy and Configuration</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deployment and Config</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deployment and Config</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deployment and Config</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deployment and Config</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/automated_deploy_and_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/automated_deploy_and_config/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Automated Deployment and Configuration</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/automated_deploy_and_configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/automated_deploy_and_configuration/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Backup Datastore: Rsync</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/rsync/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/rsync/</guid>
      <description>RSync is an open source file transfer utility that is included with most distributions of Linux. This backup utility is provided with the Community Edition (CE) of OpenNebula and supports both full and incremental backup methods.&#xA;Step 0. Setup the backup server First, a server should be configured to receive and store these backup files. The rsync backup server can be any server which is accessible from the oneadmin user on the hosts.</description>
    </item>
    <item>
      <title>Backup Jobs</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_backups/backup_jobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_backups/backup_jobs/</guid>
      <description>Overview Backup Jobs enable you to define backup operations that involve multiple VMs, simplifying the management of your cloud infrastructure. With Backup Jobs, you can:&#xA;Establish a unified backup policy for multiple VMs, encompassing schedules, backup retention, and filesystem freeze mode. Maintain control over the execution of backup operations, ensuring they do not disrupt your ongoing workloads. Monitor the progress of backup operations, allowing you to estimate backup times accurately.</description>
    </item>
    <item>
      <title>Build Dependencies</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/build_deps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/build_deps/</guid>
      <description>This page lists the build dependencies for OpenNebula.&#xA;g++ compiler (&amp;gt;= 5.0) xmlrpc-c development libraries (&amp;gt;= 1.06) scons build tool (&amp;gt;= 0.98) sqlite3 development libraries (if compiling with sqlite support) (&amp;gt;= 3.6) mysql client development libraries (if compiling with mysql support) (&amp;gt;= 5.1, &amp;gt;= 5.6 is recommended for pool search) libxml2 development libraries (&amp;gt;= 2.7) libvncserver development libraries (&amp;gt;= 0.9) openssl development libraries (&amp;gt;= 0.9.8) ruby interpreter (&amp;gt;= 2.0.0) Ubuntu 22.</description>
    </item>
    <item>
      <title>Cloud Access Model and Roles</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/cloud_access_model_and_roles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/cloud_access_model_and_roles/</guid>
      <description>In a small installation with a few hosts you can use OpenNebula without giving much thought to infrastructure partitioning and provisioning. Yet, for medium and large-scale deployments you will probably want to provide some level of isolation and structure. OpenNebula offers a flexible and powerful cloud provisioning model based on Virtual Data Centers (VDCs) that enables an integrated, comprehensive framework to dynamically provision the infrastructure resources in large multi-datacenter and multi-cloud environments to different customers, business units or groups.</description>
    </item>
    <item>
      <title>Cloud Deployment - Shared Storage</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/automatic_deployment_of_opennebula_with_one_deploy/one_deploy_tutorial_shared_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/automatic_deployment_of_opennebula_with_one_deploy/one_deploy_tutorial_shared_ds/</guid>
      <description>Overview In this tutorial, we’ll use OneDeploy to automatically deploy a simple OpenNebula cloud, with one Front-end and two Hosts using storage shared over NFS. In this configuration, the OpenNebula Front-end and Hypervisor nodes read datastore images from an NFS share available on the network.&#xA;This sample architecture uses a basic network configuration, a flat (bridged) network, where each VM’s IPs is part of the same network as the Hypervisors.</description>
    </item>
    <item>
      <title>Clusters</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/cluster_guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/cluster_guide/</guid>
      <description>Clusters group together Hosts, datastores and virtual networks that are configured to work together. A cluster is used to:&#xA;Ensure that VMs use resources that are compatible. Assign resources to user groups by creating Virtual Private Clouds. Clusters should contain homogeneous resources. Note that some operations like live migrations are restricted to Hosts in the same cluster.&#xA;The requirements for live migrating VMs between hosts of the same cluster are that no differences occur in the following areas of the hypervisors:</description>
    </item>
    <item>
      <title>Diff Formats</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/diff_formats/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/diff_formats/</guid>
      <description>The configuration management tool onecfg allows us to compare the configuration files to identify user changes against the OpenNebula distributed files. The result of a comparison, the differential output, describes all the individual changes which were made and which can even be applied again later or on a different machine.&#xA;The following table shows supported formats by each subcommand:&#xA;Format Description onecfg diff onecfg patch text Easy human-readable text YES (default) NO line Single line for one change YES YES (default) yaml Complete change structure YES YES Only line format will be described in a detail, as it’s powerful in achieving even complex changes and easy enough to read or write manually.</description>
    </item>
    <item>
      <title>Equinix Edge Cluster</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/equinix_cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/equinix_cluster/</guid>
      <description>Edge Cluster Types Equinix supports metal edge clusters that use bare-metal instances to create OpenNebula Hosts. Metal provisions can run the LXC or KVM hypervisors.&#xA;Equinix Edge Cluster Implementation An Edge Cluster in Equinix creates the following resources:&#xA;Packet Device: Host to run virtual machines. The network model is implemented in the following way:&#xA;Public Networking: this is implemented using elastic IPs from Equinix and the IPAM driver from OpenNebula.</description>
    </item>
    <item>
      <title>Equinix Provider</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/equinix_provider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/equinix_provider/</guid>
      <description>An Equinix provider contains the credentials to interact with Equinix and also the location to deploy your Provisions. OpenNebula comes with four pre-defined providers in the following regions:&#xA;Amsterdam Parsippany (NJ, US) Tokyo California (US) In order to define an Equinix provider, you need the following information:&#xA;Credentials: these are used to interact with the remote provider. You need to provide token and project. You can follow this guide to get this data.</description>
    </item>
    <item>
      <title>Federation Usage</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/data_center_federation/usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/data_center_federation/usage/</guid>
      <description>A user will have access to all the Zones where at least one of his or her groups has VDC resources. This access be can done through Sunstone or the CLI.&#xA;Sunstone In the upper right corner of the Sunstone page, users will see a globe icon next to the name of the Zone currently being used. If the user clicks on that, he or she will get a dropdown with all the accessible Zones.</description>
    </item>
    <item>
      <title>FireEdge for Large Deployments</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/fireedge_for_large_deployments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/fireedge_for_large_deployments/</guid>
      <description>Low to medium size enterprise clouds will typically deploy FireEdge on a single machine with the other OpenNebula daemons as part. However, this simple deployment can be extended by&#xA;Improving scalability of the server for large user pools, usually by deploying FireEdge as a separate application on one or more hosts. This guide introduces various deployment options to achieve this. Check also the API Scalability guide for tips on how to improve FireEdge and OpenNebula Daemon performance.</description>
    </item>
    <item>
      <title>Grafana Visualization</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/grafana/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/grafana/</guid>
      <description>Requirements This guide assumes you already have a up and running Grafana service. If you do not already have Grafana installed, refer to the following guides:&#xA;Download and Installation. Add a new Prometheus Data sources. Note Prometheus is listening on the standard port (9090) as described in the installation guide. Grafana Dashboards We provide three dashboard templates that can be customized to your needs:&#xA;Dashboard to visualize Virtual Machine information: /usr/share/one/grafana/dashboards/vms.</description>
    </item>
    <item>
      <title>Group Admin View</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/groupadmin_view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/groupadmin_view/</guid>
      <description>The role of a Group Admin is to manage all the virtual resources of the Group, including the creation of new users. It’s like a limited version of the cloud administrator view. You can read more about OpenNebula’s approach to Groups and VDC’s from the perspective of different user roles in the Understanding OpenNebula guide.&#xA;Manage Users The Group Admin can create new user accounts, that will belong to the same Group.</description>
    </item>
    <item>
      <title>Groups</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/manage_groups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/manage_groups/</guid>
      <description>A group in OpenNebula makes it possible to isolate users and resources. A user can see and use the shared resources from other users.&#xA;The group is an authorization boundary for the users, but you can also partition your cloud infrastructure and define what resources are available to each group using Virtual Data Centers (VDC). You can read more about OpenNebula’s approach to VDCs and the cloud from the perspective of different user roles in the Understanding OpenNebula guide.</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Hardware Specification and Architecture</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/hardware_spec_and_architecture/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>How To Maintain An Appliance</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/appliances/how_to_maintain_an_appliance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/appliances_and_extensions/appliances/how_to_maintain_an_appliance/</guid>
      <description>Placeholder text for page to be written.</description>
    </item>
    <item>
      <title>KVM Driver</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/kvm_node_deployment/kvm_driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/kvm_node_deployment/kvm_driver/</guid>
      <description>Requirements The Hosts will need a CPU with Intel VT or AMD’s AMD-V features in order to support virtualization. KVM’s Preparing to use KVM guide will clarify any doubts you may have regarding whether your hardware supports KVM.&#xA;KVM will be installed and configured after following the KVM Host Installation section.&#xA;Considerations &amp;amp; Limitations Try to use virtio whenever possible, both for networks and disks. Using emulated hardware, both for networks and disks, will have an impact on performance and will not expose all the available functionality.</description>
    </item>
    <item>
      <title>Linux Containers Marketplace</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/public_marketplaces/lxc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/public_marketplaces/lxc/</guid>
      <description>The Linux Containers image server hosts a public image server with container images for LXC. OpenNebula’s Linux Containers marketplace enable users to easily download, contextualize and add Linux containers images to an OpenNebula datastore.&#xA;Note A log file (/var/log/chroot.log) is created inside the imported image filesystem with information about the operations done during the setup process; in case of issues it could be a useful source of information. Requirements Approximately 6GB of storage plus the container image size.</description>
    </item>
    <item>
      <title>LXC Driver</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/lxc_node_deployment/lxc_driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/lxc_node_deployment/lxc_driver/</guid>
      <description>Requirements LXC version &amp;gt;= 3.0.3 installed on the host. cgroup version 1 or 2 hosts are required to implement resource control operations (e.g. CPU pinning, memory or swap limitations). Considerations &amp;amp; Limitations Privileged Containers and Security In order to ensure the security in a multitenant environment, by default, the containers created by the LXC driver will be unprivileged. The unprivileged containers will be deployed as root. It will use 600100001-600165537 sub UID/GID range for mapping users/groups in order to increase security in case a malicious agent is able to escape the container.</description>
    </item>
    <item>
      <title>NFS/NAS Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/nas_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/nas_ds/</guid>
      <description>This storage configuration assumes that your Hosts can access and mount a shared volume located on a NAS (Network Attached Storage) server. You will use this shared volume to store VM disk images files. The Virtual Machines will boot also from the shared volume.&#xA;The scalability of this solution will be bound to the performance of your NAS server. However, you can use multiple NAS server simultaneously to improve the scalability of your OpenNebula cloud.</description>
    </item>
    <item>
      <title>Node Setup</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/node/</guid>
      <description>This guide includes specific node setup steps to enable each network mode. You only need to apply the corresponding section to the selected mode.&#xA;Bridged Networking Mode Requirements The OpenNebula node packages are installed. See the KVM node and LXC node installation sections for more details. Configuration No additional configuration is needed. If BRIDGE configured in the Virtual Network does not exist, a new Linux bridge will be created when the VM is instantiated.</description>
    </item>
    <item>
      <title>On-Premise HCI Cluster</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/hci_cluster_provisions/onprem_cluster_ceph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/hci_cluster_provisions/onprem_cluster_ceph/</guid>
      <description>On-Premises HCI Implementation An On-Premises Edge Cluster with Ceph consists of a set of hosts with the following requirements:&#xA;Host Subsystem Configuration &amp;amp; Requirements Operating System Ubuntu 20.04 Focal installation. SSH is configured in the host to grant root passwordless access with the oneadmin credentials. Networking Configured management interface. The OpenNebula front-end can reach the hosts through this network. Separated interface connected to the Internet. VMs will access the Internet through this network.</description>
    </item>
    <item>
      <title>OneFlow Services Auto-scaling</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/appflow_elasticity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/appflow_elasticity/</guid>
      <description>A Service Role’s cardinality can be adjusted either manually, or automatically in two ways: based on metrics or based on a schedule.&#xA;Overview When a scaling action starts, the Role and Service enter the SCALING state. In this state, the Role will instantiate or terminate a number of VMs to reach its new cardinality.&#xA;A Role with elasticity policies must define a minimum and maximum number of VMs:&#xA;&amp;#34;roles&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;frontend&amp;#34;, &amp;#34;cardinality&amp;#34;: 1, &amp;#34;vm_template&amp;#34;: 0, &amp;#34;min_vms&amp;#34; : 1, &amp;#34;max_vms&amp;#34; : 5, .</description>
    </item>
    <item>
      <title>OneKE Service (K8s)</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/oneke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/oneke/</guid>
      <description>OneKE is a minimal hyperconverged Kubernetes platform that comes with OpenNebula out of the box. OneKE is based on RKE2 - Rancher’s Next Generation Kubernetes Distribution with preinstalled components to handle:&#xA;storage persistence, ingress traffic, load balancing. The full documentation of the OneKE appliance is maintained in the OpenNebula Apps project.</description>
    </item>
    <item>
      <title>Open Cloud Reference Architecture</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/cloud_architecture_and_design/open_cloud_reference_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/cloud_architecture_and_design/open_cloud_reference_architecture/</guid>
      <description>The OpenNebula Cloud Reference Architecture is a blueprint to guide IT architects, consultants, cloud‬ ‭administrators, and field practitioners in the design and deployment of private, hybrid, and edge clouds‬ ‭fully based on ‬‭open source platforms and technologies‭. ‬‭It is based on the collective information and‬ ‭experiences of hundreds of users and client engagements. Besides the main logical components and‬ ‭interrelationships within the architecture, this document includes references to software products, specific‬ ‭configurations, and requirements of infrastructure platforms recommended for a‬‭ smooth OpenNebula‬ ‭installation‭.</description>
    </item>
    <item>
      <title>OpenNebula Repositories</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/opennebula_repository_configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/opennebula_repository_configuration/</guid>
      <description>Before we can proceed with installation, we have to configure the packaging tools on your Front-end host to include OpenNebula repositories. OpenNebula software is provided via two distinct distribution channels depending on the build type you are going to install:&#xA;Enterprise Edition - enterprise users facing hardened builds, Community Edition - free public builds. Follow the steps below based on your OpenNebula edition and Front-end operating system.&#xA;Enterprise Edition OpenNebula Systems provides an OpenNebula Enterprise Edition to customers with an active support subscription.</description>
    </item>
    <item>
      <title>Platform Notes</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/platform_notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/platform_notes/</guid>
      <description>This page will show you the specific considerations when using an OpenNebula cloud, according to the different supported platforms.&#xA;This is the list of the individual platform components that have been through the complete OpenNebula Quality Assurance and Certification Process.&#xA;Certified Components Version Front-End Components Component Version More information Red Hat Enterprise Linux 8, 9 Front-End Installation AlmaLinux 8, 9 Front-End Installation Ubuntu Server 22.04 (LTS), 24.04 (LTS) Front-End Installation Debian 11, 12 Front-End Installation.</description>
    </item>
    <item>
      <title>Provision Cluster Operations</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_operations/cluster_operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_operations/cluster_operations/</guid>
      <description>Edge Cluster Limitations Currently it is not possible to connect to VMs running in edge clusters through the normal Sunstone mechanisms to access VM console, such as VNC. Other mechanisms that connect to the VM’s IP, such as SSH and RDP, work as in other VMs running in local clusters. Creating a Cluster Check the steps here. You can also use the command oneprovision create:&#xA;$ oneprovision create /tmp/provision.yml ID: 0 Managing the Edge Cluster Listing The list command lists all provisions.</description>
    </item>
    <item>
      <title>Ruby OpenNebula Cloud API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/ruby/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/ruby/</guid>
      <description>This page contains the OpenNebula Cloud API Specification for Ruby. It has been designed as a wrapper for the XML-RPC methods, with some basic helpers. This means that you should be familiar with the XML-RPC API and the XML formats returned by the OpenNebula core. As stated in the XML-RPC documentation, you can download the XML Schemas (XSD) here.&#xA;API Documentation You can consult the doc online.&#xA;Usage You can use the Ruby OCA included in the OpenNebula distribution by adding the OpenNebula Ruby library path to the search path:</description>
    </item>
    <item>
      <title>S3 Marketplace</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/private_marketplaces/market_s3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_configuration/private_marketplaces/market_s3/</guid>
      <description>Overview This Marketplace uses an S3 API-capable service as the Back-end. This means Marketplace Appliances will be stored in the official AWS S3 service , or in services that implement that API, like Ceph Object Gateway S3.&#xA;Limitations Since the S3 API does not provide a value for available space, this space is hard-coded into the driver file, limiting it to 1TB. See below to learn how to change the default value.</description>
    </item>
    <item>
      <title>Scheduler Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/scheduler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/scheduler/</guid>
      <description>The OpenNebula Scheduler is responsible for planning of the pending Virtual Machines on available hypervisor Nodes. It’s a dedicated daemon installed alongside the OpenNebula Daemon (oned), but can be deployed independently on a different machine. The Scheduler is distributed as an operating system package opennebula with the system service opennebula-scheduler.&#xA;Scheduling Algorithm OpenNebula comes with a match-making scheduler (/usr/bin/mm_sched) that implements the Rank Scheduling Policy. The goal of this policy is to prioritize those resources more suitable for the VM.</description>
    </item>
    <item>
      <title>Security Groups</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/security_groups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/security_groups/</guid>
      <description>Security Groups define firewall rules to be applied to Virtual Machines.&#xA;Warning Security groups are not supported for OpenvSwitch. In vCenter environments, NSX is mandatory to enable Security Groups functionality. Defining a Security Group A Security Group is composed of several Rules. Each Rule is defined with the following attributes:&#xA;Attribute Type Meaning Values PROTOCOL Mandatory Defines the protocol of the rule ALL, TCP, UDP, ICMP, IPSEC RULE_TYPE Mandatory Defines the traffic direction INBOUND, OUTBOUND IP Optional If the rule only applies to a specific net.</description>
    </item>
    <item>
      <title>Storage Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/sd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/sd/</guid>
      <description>The Storage subsystem is highly modular. These drivers are separated into two logical sets:&#xA;DS: Datastore drivers. They serve the purpose of managing images: register, delete, and create empty datablocks. TM: Transfer Manager drivers. They manage images associated with instantiated VMs. Datastore Drivers Structure Located under /var/lib/one/remotes/datastore/&amp;lt;ds_mad&amp;gt;&#xA;cp: copies/dumps the image to the datastore ARGUMENTS: image_id STDIN: datastore_image_dump RETURNS: image_source image_format datastore_image_dump is an XML dump of the driver action encoded in Base 64.</description>
    </item>
    <item>
      <title>Try OpenNebula Front-end on AWS</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/try_opennebula_on_kvm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/try_opennebula_on_kvm/</guid>
      <description>In this tutorial, we’ll install an OpenNebula Front-end in under ten minutes, using miniONE, the installation script provided by OpenNebula.&#xA;We’ll install our OpenNebula Front-end on a Virtual Machine in AWS. In later sections of this Quick Start Guide, you can use this Front-end to provision additional resources — such as Edge clusters or Kubernetes clusters — on your OpenNebula cloud.&#xA;To complete this tutorial, you will need an AWS account with the capacity to create a virtual machine and obtain public IP addresses.</description>
    </item>
    <item>
      <title>Upgrading Single Front-End</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrading_single/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrading_single/</guid>
      <description>Important Users of the Community Edition of OpenNebula can upgrade from the previous stable version if they are running a non-commercial OpenNebula cloud. In order to access the migrator package a request needs to be made through this online form. In order to use these non-commercial migrators to upgrade to the latest CE release (OpenNebula 6.8.0), you will need to upgrade your existing OpenNebula environment first to CE Patch Release 6.</description>
    </item>
    <item>
      <title>Usage Quotas</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/capacity_planning/quotas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/capacity_planning/quotas/</guid>
      <description>The quota system tracks user and group usage of system resources, and allows the system administrator to set limits on the usage of these resources. Quota limits can be set for:&#xA;users, to individually limit the usage made by a given user. groups, to limit the overall usage made by all the users in a given group. This can be of special interest for the OpenNebula Zones and Virtual Data Center (VDC) components.</description>
    </item>
    <item>
      <title>Virtual Machine Affinity</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/affinity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/affinity/</guid>
      <description>A VM Group defines a set of related VMs, and associated placement constraints for the VMs in the group. A VM Group allows you to place together (or separately) certain VMs (or VM classes, called roles). VMGroups will help you to optimize the performance (e.g. not placing all the CPU bound VMs in the same host) or improve the fault tolerance (e.g. not placing all your front-ends in the same host) of your multi-VM applications.</description>
    </item>
    <item>
      <title>Virtual Machine Templates</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_images/vm_templates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machine_images/vm_templates/</guid>
      <description>In OpenNebula, VMs are defined with VM Templates. This section explains how to describe a Virtual Machine, and how users typically interact with the system.&#xA;OpenNebula administrators and users can register Virtual Machine definitions (VM Templates) in the system, to be instantiated later as Virtual Machine instances. These VM Templates can be instantiated several times, and also shared with other users.&#xA;Defining a VM A Virtual Machine Template, at the very basics, consists of:</description>
    </item>
    <item>
      <title>Virtual Network Template</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/vnet_template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/vnet_template/</guid>
      <description>This page describes how to define a new Virtual Network. A Virtual Network includes three different aspects:&#xA;Physical network attributes. Address Range. Configuration attributes for the guests. When writing a Virtual Network template in a file, it follows the same syntax as the VM template.&#xA;Physical Network Attributes It defines the underlying networking infrastructure that will support the Virtual Network, such as the VLAN ID or the hypervisor interface to bind the Virtual Network to.</description>
    </item>
    <item>
      <title>Virtual Objects Provisioning</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/virtual/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/virtual/</guid>
      <description>With OneProvision you can grow up the physical resources available in your cloud. Once you have your infrastructure ready, you need to create virtual objects in it, in order to use it. In this section we are going to show a way to deploy everything at once with OneProvision.&#xA;Managing Virtual Objects In this section you can check how to create all the virtual objects you need to have a cluster ready to instantiate a virtual machine.</description>
    </item>
    <item>
      <title>VM HA</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/high_availability/vm_ha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/high_availability/vm_ha/</guid>
      <description>The goal of this section is to provide information to prepare for failures of the Virtual Machines or Hosts and to recover from them. These failures are categorized depending on whether they come from the physical infrastructure (Host failures) or from the virtualized infrastructure (VM crashes). In both scenarios, OpenNebula provides a cost-effective failover solution to minimize downtime from server and OS failures.&#xA;Host Failures When OpenNebula detects that a Host is down, a hook can be triggered to deal with the situation.</description>
    </item>
    <item>
      <title>WHMCS Admin Usage</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/admin_usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/admin_usage/</guid>
      <description>Creating a Product Group Before creating products you should create groups to better organize your offerings. To create a new product group, navigate to System Settings -&amp;gt; Products/Services, then click on the Create a New Group button there. Fill in the Product Group Name, and any other pieces of this form such as Template and Payment Gateways, then click Save Changes once you’re done.&#xA;Creating a Product Navigate to System Settings -&amp;gt; Products/Services.</description>
    </item>
    <item>
      <title>Windows Best Practices</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/windows_best_practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/windows_best_practice/</guid>
      <description>Windows as a guest operating system on KVM hypervisors requires some additional configuration in order to achieve performant virtual machines. In this document we’ll go over the best practices for deploying your Windows Virtual Machine, and provide some extra actions that can be taken in Windows after deployment to improve performance.&#xA;Resource Allocations Template Configuration Post Deployment actions The best way to achieve high performance when using this guide is to also use higher performing hardware, the disk will be the most relevant and performance will be greatly impacted on systems with HDDs rather than SSD/NVMe.</description>
    </item>
    <item>
      <title>X.509 Authentication</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/x509/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/x509/</guid>
      <description>This guide will show you how to enable and use authentication using X.509 certificates with OpenNebula with authentication driver x509. The X.509 certificates can be used in two different ways in OpenNebula.&#xA;The first option that is explained in this guide enables us to use certificates with the CLI. In this case the user will generate a login token with their private key. OpenNebula will validate the certificate and decrypt the token to authenticate the user.</description>
    </item>
    <item>
      <title>Advanced SSH Usage</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/advanced_ssh_usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/large-scale_deployment/advanced_ssh_usage/</guid>
      <description>This guide covers advanced SSH configuration for OpenNebula nodes, specifically:&#xA;integrated OpenNebula SSH Authentication Agent SSH client configuration gathering of host SSH public keys Note This section extends the Configure Passwordless SSH step within the Node installation guides with advanced SSH configuration and usage. Authentication Agent OpenNebula’s integrated SSH Authentication Agent service is automatically started on the Front-end by implicit dependencies of OpenNebula. During startup, it imports the default SSH private keys of oneadmin user from the directory /var/lib/one/.</description>
    </item>
    <item>
      <title>Alert Manager</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/alerts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/alerts/</guid>
      <description>Installation and Configuration Note If you are already running the Prometheus AlertManager you can skip this section and add the alarms described in the next section to your rules file. AlertManager is part of the Prometheus distribution and should already be installed in your system after completing the installation process, see more details here.&#xA;Now you just need to enable and start the AlertManager service:&#xA;# systemctl enable --now opennebula-alertmanager.</description>
    </item>
    <item>
      <title>Bridged Networking</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/bridged/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/bridged/</guid>
      <description>This guide describes how to deploy Bridged networks. In this mode, the virtual machine traffic is directly bridged through the Linux bridge on the hypervisor Nodes. Bridged networks can operate in four different modes depending on the additional traffic filtering made by OpenNebula:&#xA;Dummy Bridged, no filtering, no bridge setup (legacy no-op driver). Bridged, no filtering is made, managed bridge. Bridged with Security Groups, iptables rules are installed to implement security groups rules.</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/5g-ready_opennebula/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/ai-ready_opennebula/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/arm-ready_opennebula/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_for_deployment_cases/confidential_opennebula/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/ovh_opennebula-onprem_cloud_solution/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_cloud_providers/scaleway_opennebula-onprem_cloud_solution/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/ampere_opennebula-onprem_cloud_solution/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/dell_opennebula-onprem_cloud_solution/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Certification</title>
      <link>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/deployment_framework/reference_architecture_guides_with_hw_vendors/hpe_opennebula-onprem_cloud_solution/certification/</guid>
      <description>TBC</description>
    </item>
    <item>
      <title>Command Line Interface</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/cli/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/cli/</guid>
      <description>OpenNebula provides a set commands to interact with the system:&#xA;CLI oneacct: gets accounting data from OpenNebula. oneacl: manages OpenNebula ACLs. onecfg: manages OpenNebula configuration files upgrade. onecluster: manages OpenNebula clusters. onedatastore: manages OpenNebula datastores. onedb: OpenNebula database migration tool. onegroup: manages OpenNebula groups. onehook: manages OpenNebula hooks. onehost: manages OpenNebula hosts. oneimage: manages OpenNebula images. onemarket: manages internal and external marketplaces. onemarketapp: manages appliances from marketplaces. oneprovider: manages OpenNebula providers.</description>
    </item>
    <item>
      <title>External Schedulers</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/external/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/scheduling/external/</guid>
      <description>The default OpenNebula scheduler can interface with external schedulers to implement additional algorithms tailored to your specific use case or business logic. Communication is established through a straightforward REST API. This guide will walk you through configuring and developing your own external scheduler.&#xA;External Scheduler API The scheduler employs a simple REST API. When the external scheduler is configured, the OpenNebula scheduler triggers a POST operation to the designated URL.</description>
    </item>
    <item>
      <title>Knowledge Base</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/knowledge_base/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/knowledge_base/</guid>
      <description>&#xA;The OpenNebula Customer Portal provides exclusive answers to common questions and issues, as well as best practices to deploy and operate an OpenNebula cloud. Although most of the contents are only available for customers with an active subscription, the portal also includes open content for the whole community.&#xA;Note Open content in our Enterprise Portal. </description>
    </item>
    <item>
      <title>LDAP Authentication</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/ldap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/ldap/</guid>
      <description>The LDAP Authentication allows users to have the same credentials as in LDAP, effectively centralizing authentication. Enabling it will let any correctly authenticated LDAP user use OpenNebula.&#xA;Requirements You need to have your own LDAP server in the infrastructure. OpenNebula doesn’t contain or configure any LDAP server, it only connects to an existing one. Also, it doesn’t create, delete or modify any entry in the LDAP server it connects to.</description>
    </item>
    <item>
      <title>Local Storage Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/local_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/local_ds/</guid>
      <description>This storage configuration uses the local storage area of each Host to run VMs. Additionally you’ll need a storage area for the VM disk image repository. Disk images are transferred from the repository to the hosts using the SSH protocol.&#xA;Front-end Setup The Front-end needs to prepare the storage area for:&#xA;Image Datastores, to store the image repository. System Datastores, will hold temporary disks and files for VMs stopped and undeployed.</description>
    </item>
    <item>
      <title>Monitoring Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/monitoring/</guid>
      <description>The monitoring subsystem is represented by a dedicated daemon (onemonitord) running as part of the OpenNebula Daemon (oned), that gathers information relevant to the Hosts and the Virtual Machines, e.g. Host status, basic performance indicators, Virtual Machine status, and capacity consumption. This information is collected by executing a set of probe programs provided by OpenNebula. The output of these probes is sent to OpenNebula using a push mechanism. It’s part of the operating system package opennebula.</description>
    </item>
    <item>
      <title>Monitoring Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-im/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-im/</guid>
      <description>The Monitoring Drivers (or IM drivers) collect host and virtual machine monitoring data by executing a monitoring agent in the hosts. The agent periodically executes probes to collect data and periodically send them to the frontend.&#xA;This guide describes the internals of the monitoring system. It is also a starting point on how to create a new IM driver from scratch.&#xA;Message structure The structure of monitoring message is:</description>
    </item>
    <item>
      <title>OneGate Usage</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/onegate_usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/multi-vm_workflows/onegate_usage/</guid>
      <description>The OneGate component allows Virtual Machine guests to pull and push VM information from OpenNebula. Users and administrators can use it to gather metrics, detect problems in their applications, and trigger OneFlow elasticity rules from inside the VM.&#xA;For Virtual Machines that are part of a Multi-VM Application (OneFlow Service), they can also retrieve the Service information directly from OneGate and trigger actions to reconfigure the Service or pass information among different VMs.</description>
    </item>
    <item>
      <title>OneSwap</title>
      <link>https://opennebula.github.io/website/docs/tools/oneswap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/tools/oneswap/</guid>
      <description>Placeholder text for page that needs to be written, probably linking to the GitHub repo or the wiki.</description>
    </item>
    <item>
      <title>Operating System Profiles</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/os_profile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/guest_operating_systems/os_profile/</guid>
      <description>In Sunstone you can quickly flavor a VM template by using a Operating System Profile, which will pre-fill part of the template for you. By default Sunstone ships with a default “Windows Optimized” profile which contains some basic windows specific optimization settings.&#xA;Defining a Profile Navigate to the profiles directory&#xA;By default found in etc/one/fireedge/sunstone/profiles.&#xA;Create a new YAML file&#xA;Name your profile by defining a new .yaml file</description>
    </item>
    <item>
      <title>Provision Template Reference</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/operations_and_references/hybrid_cluster_references/template/</guid>
      <description>The provision is a process of allocating new physical resources from the remote providers. All the information needed is stored in the provision template file and passed to the oneprovision create command.&#xA;In this chapter, we’ll describe the format and content of the provision template.&#xA;A provision template is a YAML-formatted file with parameters specifying the new physical resources to be provisioned. It contains:&#xA;header (name, configuration playbook, parent template) global default parameters for remote connection (SSH), host provision driver, host configuration tunables.</description>
    </item>
    <item>
      <title>Python OpenNebula Cloud API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/python/</guid>
      <description>PyONE is an implementation of OpenNebula XML-RPC bindings in Python. It has been designed as a wrapper for the XML-RPC methods, with some basic helpers. This means that you should be familiar with the XML-RPC API and the XML formats returned by the OpenNebula core. As stated in the XML-RPC documentation, you can download the XML Schemas (XSD) here.&#xA;API Documentation As long as the code is generated, the main source of the documentation is still the XML-RPC doc</description>
    </item>
    <item>
      <title>Scaleway Edge Cluster</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/scaleway_cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/scaleway_cluster/</guid>
      <description>Edge Cluster Types Equinix supports metal edge clusters that use bare-metal instances to create OpenNebula Hosts. Metal provisions can run the LXC or KVM hypervisors.&#xA;Scaleway Edge Cluster Implementation An Edge Cluster in Scaleway creates the following resources:&#xA;Scaleway Elastic Metal Device: Host to run virtual machines. Scaleway VPC: it creates an isolated virtual network for all the deployed resources. Scaleway private subnet: it allows communication between VMs that are running in the provisioned Hosts.</description>
    </item>
    <item>
      <title>Scaleway Provider</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/scaleway_provider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/scaleway_provider/</guid>
      <description>A Scaleway provider contains the credentials to interact with Scaleway and also the location to deploy your Provisions. OpenNebula comes with three pre-defined providers in the following regions:&#xA;PAR-1 (France - Paris) NL-AMS-1 (Netherlands - Amsterdam) PL-WAW-3 (Poland - Warsaw) In order to define a Scaleway provider, you need the following information:&#xA;Credentials: these are used to interact with the remote provider. You need to provide access_key, secret_key and project_id.</description>
    </item>
    <item>
      <title>Secondary Platforms</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/secondary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/secondary/</guid>
      <description>Secondary Platforms are experimental OpenNebula builds for bleeding edge operating systems and software versions, a completely new platform which hasn’t gained mature support in OpenNebula yet, or for non-mainstream CPU architectures. Continuity of support is not guaranteed. Builds for the Secondary Platforms are provided with only limited testing coverage and without any commercial support options.&#xA;Important Secondary Platforms are not recommended for production environments, nor officially supported by OpenNebula Systems.</description>
    </item>
    <item>
      <title>Self Provision</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/self_provision/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/self_provision/</guid>
      <description>End-users can create their own virtual networks in two different ways:&#xA;making a reservation instantiating a Virtual Network Template. Reservations Reservations allows users to create their own networks consisting on portions of an existing Virtual Network. Each portion is called a Reservation. To implement this you need to:&#xA;Define a VNET, with the desired ARs and configuration attributes. These attributes will be inherited by any Reservation, so the final users do not need to deal with low-level networking details.</description>
    </item>
    <item>
      <title>Single Front-end Installation</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/package_installation_references/front_end_installation/install/</guid>
      <description>This page describes how to install a complete OpenNebula Front-end from binary packages available in the software repositories configured in the previous section. We recommend using a Host with the supported operating system as installation from packages provides the best experience and is referenced from other places of this documentation. If there are no packages for your distribution, you might consider reading the Building from Source Code guide to build OpenNebula on your own.</description>
    </item>
    <item>
      <title>Sunstone Development</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/sunstone_dev/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/sunstone_dev/</guid>
      <description>OpenNebula FireEdge server provides a next-generation web-management interface.&#xA;Sunstone GUI: &amp;lt;http://&amp;lt;OPENNEBULA-FRONTEND&amp;gt;:2616/fireedge/sunstone&amp;gt; (automatically redirected from &amp;lt;http://&amp;lt;OPENNEBULA-FRONTEND&amp;gt;:2616/) This second Sunstone incarnation is written in React / Redux and Material-UI is used for the styles and layout of the web.&#xA;If you want to do development work over Sunstone, you need to install OpenNebula from source. For this, you will need build dependencies, git, nodeJS v12 and npm v6.&#xA;Once the environment has been prepared, you need to clone one repository and follow the steps to compile the OpenNebula software.</description>
    </item>
    <item>
      <title>Sunstone Labels</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/sunstone_labels/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/sunstone_labels/</guid>
      <description>Labels can be defined for most of the OpenNebula resources from the admin view.&#xA;Each resource will store the label information in its own template, thus it can be easily edited from the CLI or Sunstone.&#xA;This feature enables the possibility to group the different resources under a given label and filter them in the admin and cloud views. The user will be able to easily find the template she wants to instantiate, or select a set of resources to apply a given action.</description>
    </item>
    <item>
      <title>Troubleshooting</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/conflicts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/conflicts/</guid>
      <description>The configuration files upgrade is a complex process, during which many problems may arise. The root cause of all problems are the users’ customizations made in the configuration files in places that also change in a newer version. Because the upgrade process tries to apply changes from newer versions to existing files, the tool can be confused when it reaches the incompatibly modified part.&#xA;In case of a problem, the upgrade process terminates and leaves the state of configuration files unchanged.</description>
    </item>
    <item>
      <title>Try OpenNebula Hosted Front-end</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/try_opennebula_hosted/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/try_opennebula_hosted/</guid>
      <description>For evaluation purposes, you can request and evaluate a complete OpenNebula Front-end running on infrastructure hosted by OpenNebula. The OpenNebula Hosted Service allows you to try OpenNebula on the KVM hypervisor, to configure it to your needs, and to provision new resources in the cloud and at the edge. You can then run and manage Virtual Machines and Kubernetes clusters.&#xA;A hosted OpenNebula installation offers two tools to create and manage resources and clusters:</description>
    </item>
    <item>
      <title>Upgrading High Availability Clusters</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrading_ha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrading_ha/</guid>
      <description>Step 1. Check Virtual Machine Status Before proceeding, make sure you don’t have any VMs in a transient state (prolog, migrate, epilog, save). Wait until these VMs get to a final state (running, suspended, stopped, done). Check the Managing Virtual Machines guide for more information on the VM life-cycle.&#xA;Step 2. Set All Hosts to Disable Mode Set all Hosts to disable mode to stop all monitoring processes.&#xA;$ onehost disable &amp;lt;host_id&amp;gt; If you are upgrading from version 6.</description>
    </item>
    <item>
      <title>VDCs</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/manage_vdcs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/manage_vdcs/</guid>
      <description>A VDC (Virtual Data Center) defines an assignment of one or several groups to a pool of physical resources. This pool of Physical Resources consists of resources from one or several Clusters that could belong to different Zones or public external clouds for hybrid cloud computing. You can read more about OpenNebula’s approach to VDCs and the cloud from the perspective of different user roles in the Understanding OpenNebula guide.</description>
    </item>
    <item>
      <title>Virtual Topology and CPU Pinning</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/numa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/numa/</guid>
      <description>Overview In this guide you’ll learn to set up OpenNebula to control how VM resources are mapped onto the hypervisor ones. These settings will help you to fine tune the performance of VMs. We will use the following concepts:&#xA;Cores, Threads and Sockets. A computer processor is connected to the motherboard through a socket. A processor can pack one or more cores, each one implements a separate processing unit that shares some cache levels, memory, and I/O ports.</description>
    </item>
    <item>
      <title>WHMCS User Guide</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/users_guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/whmcs_installation_and_usage/users_guide/</guid>
      <description>Register an Account To register a new account, navigate to the client area of your WHMCS install and then go to Account -&amp;gt; Register. Fill out the following form and proceed with user creation. After it’s completed you should be able to log in as that new user.&#xA;Order a New Service To view the available products navigate to Services -&amp;gt; Order New Services. This page will display all available services which can be purchased.</description>
    </item>
    <item>
      <title>WordPress</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/wordpress/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/wordpress/</guid>
      <description>This OpenNebula marketplace appliance comes with a preinstalled WordPress service and includes the following features:&#xA;Based on the latest AlmaLinux 8 Linux distribution (for x86-64). No default login (local or SSH) password - must be provided via contextualization The full documentation of the WordPress appliance is maintained in the OpenNebula Apps project.</description>
    </item>
    <item>
      <title>802.1Q VLAN Networks</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/vlan/</guid>
      <description>This guide describes how to enable network isolation provided through Host-managed VLANs. This driver will create a bridge for each OpenNebula Virtual Network and attach a VLAN tagged network interface to the bridge. This mechanism is compliant with IEEE 802.1Q.&#xA;The VLAN ID will be the same for every interface in a given network, automatically computed by OpenNebula. It may also be forced by specifying a VLAN_ID parameter in the Virtual Network template.</description>
    </item>
    <item>
      <title>Appendix - List of Configurations</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/appendix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/configuration_management_ee/appendix/</guid>
      <description>The following table describes all configuration files and their type from directories&#xA;/etc/one/ /var/lib/one/remotes/ managed by the onecfg tool:&#xA;Name Type /etc/one/alertmanager/alertmanager.yml YAML /etc/one/auth/ldap_auth.conf YAML w/ ordered arrays /etc/one/auth/server_x509_auth.conf YAML /etc/one/auth/x509_auth.conf YAML /etc/one/az_driver.conf YAML /etc/one/az_driver.default Plain file (or XML) /etc/one/cli/*.yaml YAML w/ ordered arrays /etc/one/defaultrc Shell /etc/one/ec2_driver.conf YAML /etc/one/ec2_driver.default Plain file (or XML) /etc/one/ec2query_templates/*.erb Plain file (or XML) /etc/one/hm/hmrc Shell /etc/one/econe.conf YAML /etc/one/fireedge-server.conf YAML /etc/one/fireedge/provision/providers.d-extra/*.yaml YAML /etc/one/fireedge/provision/providers.d/*.yaml YAML /etc/one/fireedge/provision/provision-server.conf YAML /etc/one/fireedge/sunstone/*/*.</description>
    </item>
    <item>
      <title>Ceph Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/ceph_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/ceph_ds/</guid>
      <description>The Ceph Datastore driver allows the use of Ceph storage for Images and disks of Virtual Machines.&#xA;Warning This driver requires the OpenNebula Nodes using the Ceph driver to be Ceph clients of a running Ceph cluster. More information in Ceph documentation. Ceph Cluster Setup This guide assumes that you already have a functional Ceph Cluster in place. Additionally you need to:&#xA;Create a pool for the OpenNebula datastores. Write down the name of the pool to include it in the datastore definitions.</description>
    </item>
    <item>
      <title>Cloud Servers Authentication</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/cloud_auth/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/development_references/building_from_source_code/cloud_auth/</guid>
      <description>When a user interacts with Sunstone, the server authenticates the request and then forwards the requested operation to the OpenNebula daemon.&#xA;The forwarded requests between the server and the core daemon include the original user name, and are signed with the credentials of a special server user.&#xA;In this guide this request forwarding mechanism is explained, and how it is secured with a symmetric-key algorithm.&#xA;Server Users The Sunstone server communicate with the core using a server user.</description>
    </item>
    <item>
      <title>Compatibility Guide</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/compatibility/</guid>
      <description>This guide is aimed at OpenNebula 6.10.x users and administrators who want to upgrade to the latest version. The following sections summarize the new features and usage changes that should be taken into account, or are prone to cause confusion. You can check the upgrade process in the corresponding section. If upgrading from previous versions, please make sure you read all the intermediate versions’ Compatibility Guides for possible pitfalls.</description>
    </item>
    <item>
      <title>Exporter Metrics</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/monitoring_and_alerting/metrics/</guid>
      <description>OpenNebula Exporter Name Description Type opennebula_host_total Total number of hosts defined in OpenNebula gauge opennebula_host_state Host state 0:init 2:monitored 3:error 4:disabled 8:offline gauge opennebula_host_mem_total_bytes Total memory capacity gauge opennebula_host_mem_maximum_bytes Total memory capacity considering overcommitment gauge opennebula_host_mem_usage_bytes Total memory capacity allocated to VMs gauge opennebula_host_cpu_total_ratio Total CPU capacity gauge opennebula_host_cpu_maximum_ratio Total CPU capacity considering overcommitment gauge opennebula_host_cpu_usage_ratio Total CPU capacity allocated to VMs gauge opennebula_host_vms Number of VMs allocated to the host gauge opennebula_datastore_total Total number of datastores defined in OpenNebula gauge opennebula_datastore_total_bytes Total capacity of the datastore gauge opennebula_datastore_used_bytes Capacity being used in the datastore gauge opennebula_datastore_free_bytes Available capacity in the datastore gauge opennebula_datastore_images Number of images stored in the datastore gauge opennebula_vm_total Total number of VMs defined in OpenNebula gauge opennebula_vm_host_id Host ID where the VM is allocated gauge opennebula_vm_state VM state 0:init 1:pending 2:hold 3:active 4:stopped 5:suspended 6:done 8:poweroff 9:undeployed 10:cloning gauge opennebula_vm_lcm_state VM LCM state, only relevant for state 3 (active) gauge opennebula_vm_mem_total_bytes Total memory capacity gauge opennebula_vm_cpu_ratio Total CPU capacity requested by the VM gauge opennebula_vm_cpu_vcpus Total number of virtual CPUs gauge opennebula_vm_disks Total number of disks gauge opennebula_vm_disk_size_bytes Size of the VM disk gauge opennebula_vm_nics Total number of network interfaces gauge opennebula_oned_state OpenNebula oned service state 0:down 1:up gauge opennebula_scheduler_state OpenNebula scheduler service state 0:down 1:up gauge opennebula_flow_state OpenNebula Flow service state 0:down 1:up gauge opennebula_hem_state OpenNebula hook manager service state 0:down 1:up gauge opennebula_gate_state OpenNebula Gate service state 0:down 1:up gauge Libvirt Exporter Name Description Type opennebula_libvirt_requests_total The total number of HTTP requests handled by the Rack application.</description>
    </item>
    <item>
      <title>FireEdge Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/fireedge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/fireedge/</guid>
      <description>The OpenNebula FireEdge server provides a next-generation web-management interface for remote OpenNebula Cluster provisioning (OneProvision GUI) as well as additional functionality to Sunstone. It’s a dedicated daemon installed by default as part of the Single Front-end Installation, but can be deployed independently on a different machine. The server is distributed as an operating system package opennebula-fireedge with the system service opennebula-fireedge.&#xA;Main Features Guacamole Proxy for Sunstone to remotely access the VMs (incl.</description>
    </item>
    <item>
      <title>Java OpenNebula Cloud API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/java/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/java/</guid>
      <description>This page contains the OpenNebula Cloud API Specification for Java. It has been designed as a wrapper for the XML-RPC methods, with some basic helpers. This means that you should be familiar with the XML-RPC API and the XML formats returned by the OpenNebula core. As stated in the XML-RPC documentation, you can download the XML Schemas (XSD) here.&#xA;Download You can download the .jar file compiled using Java 1.</description>
    </item>
    <item>
      <title>Networking Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-nm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-nm/</guid>
      <description>This component is in charge of configuring the network in the hypervisors. The purpose of this guide is to describe how to create a new network manager driver.&#xA;Driver Configuration and Description To enable a new network manager driver, the first requirement is to make a new directory with the name of the driver in /var/lib/one/remotes/vnm/&amp;lt;name&amp;gt; with these files:&#xA;pre: This driver should perform all the network related actions required before the Virtual Machine starts in a host.</description>
    </item>
    <item>
      <title>On-Premise Edge Cluster</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/onprem_cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_cluster_provisions/onprem_cluster/</guid>
      <description>Edge Cluster Types On-Premises metal edge clusters use bare-metal servers in your datacenter. Metal provisions can run the LXC or KVM hypervisors.&#xA;On-Premises Edge Cluster Implementation An On-Premises Edge Cluster consists of a set of servers with the following requirements:&#xA;Host Subsystem Configuration &amp;amp; Requirements Operating System Ubuntu 20.04 Focal installation. SSH is configured in the host to grant root passwordless access with the oneadmin credentials. Networking Configured management interface.</description>
    </item>
    <item>
      <title>On-Premise Provider</title>
      <link>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/onprem_provider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/hybrid_multi_cloud/automated_hybrid_cluster_provisioning/edge_and_cloud_providers/onprem_provider/</guid>
      <description>The onprem provider is a convenient abstraction to represent your local resources. This provider can be used to automatically configure and install OpenNebula clusters using your on-premises servers. It needs no special configuration as it will retrieve the FQDNs or IP addresses of the hosts while creating the provisions.&#xA;How to Create the On-Premises Provider You just need to create the on-premises provider once, simply run the following command:</description>
    </item>
    <item>
      <title>PCI Passthrough</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/pci_passthrough/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/pci_passthrough/</guid>
      <description>It is possible to discover PCI devices in the Hosts and directly assign them to Virtual Machines in the KVM hypervisor.&#xA;The setup and environment information is taken from here. You can safely ignore all the VGA related sections, those for PCI devices that are not graphic cards, or if you don’t want to output video signal from them.&#xA;Warning The overall setup state was extracted from a preconfigured Fedora 22 machine.</description>
    </item>
    <item>
      <title>Provisioning a Cloud Cluster</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/provisioning_edge_cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/provisioning_edge_cluster/</guid>
      <description>In the first tutorial of this Quick Start Guide, we installed an OpenNebula Front-end on AWS. In this tutorial, we’ll use that Front-end to provision an Edge Cluster on AWS, using the Sunstone GUI for the whole process, in just a few clicks.&#xA;The edge cluster we’ll create includes a KVM hypervisor. It’s a suitable platform for deploying both Virtual Machines and Kubernetes clusters.&#xA;To create the cluster, we’ll follow these high-level steps:</description>
    </item>
    <item>
      <title>Sunstone</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/fireedge_sunstone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/control_plane_configuration/graphical_user_interface/fireedge_sunstone/</guid>
      <description>Overview Sunstone is the new generation OpenNebula web interface, fully featured for VM and VM Template management and with other sections ready covering most functionality for end users.&#xA;This interface is delivered by the FireEdge server, and it is its main interface, meaning that it will redirect to Sunstone when contacted in the http://&amp;lt;OPENNEBULA-FRONTEND&amp;gt;:2616/ address.&#xA;Configuration To configure Sunstone, there are several options to consider, and they are described in the FireEdge Configuration guide.</description>
    </item>
    <item>
      <title>Sunstone Authentication</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/sunstone_auth/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/authentication_configuration/sunstone_auth/</guid>
      <description>By default, Sunstone works with the default core authentication method (user and password) although you can configure any authentication mechanism supported by OpenNebula. In this section, you will learn how to enable other authentication.&#xA;Authentication is based on the credentials stored in the OpenNebula database for the user. Depending on the type of these credentials the authentication method can be: remote or opennebula. The following sections explain the client to Sunstone server authentication methods.</description>
    </item>
    <item>
      <title>Sunstone Views</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/fireedge_sunstone_views/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/fireedge_sunstone_views/</guid>
      <description>Using the OpenNebula FireEdge Sunstone Views you will be able to provide a simplified UI aimed at end-users of an OpenNebula cloud. The OpenNebula FireEdge Sunstone Views are fully customizable, so you can easily enable or disable specific information tabs or action buttons. You can define multiple views for different user groups. You can define multiple views for different user groups. Each view defines a set of UI components, so each user just accesses and views the relevant parts of the cloud for her role.</description>
    </item>
    <item>
      <title>Upgrading Federated Instances</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrading_federation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrading_federation/</guid>
      <description>This version of OpenNebula introduces some changes in the federation data model. You need to coordinate the upgrade across zones and upgrade them at the same time.&#xA;Step 1. Check Federation Status Check that federation is in sync and all zones are at the same index (FED_INDEX):&#xA;$ onezone list C ID NAME ENDPOINT FED_INDEX 101 S-US-CA http://192.168.150.3:2633/RPC2 715438 100 S-EU-GE http://192.168.150.2:2633/RPC2 715438 * 0 M-EU-FR http://192.168.150.1:2633/RPC2 715438 It is a good idea to prevent any API access to the master zone during this step (e.</description>
    </item>
    <item>
      <title>Use Cases</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/use_cases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/understand_opennebula/opennebula_concepts/use_cases/</guid>
      <description>Screencasts Browse the ever-expanding catalog of screencasts created by the OpenNebula Team to showcase interesting applications and integrations with third-party technologies and other open source projects.&#xA;Note Browse the catalog of screencasts and tutorial videos here. User Stories OpenNebula is used to implement different types of cloud deployments, from clouds tuned to address the demands of a niche market to clouds optimized to manage the virtualized resources in the data center.</description>
    </item>
    <item>
      <title>Virtual Machine States Reference</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/vm_states/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/vm_states/</guid>
      <description>This page is a complete reference of all the VM states that will be useful for administrators doing troubleshooting and developers.&#xA;The simplified life-cycle is explained in the Managing Virtual Machines guide. That simplified diagram uses a smaller number of state names. These names are the ones used by onevm list, e.g. prolog, prolog_migrate and prolog_resume are all presented as prol. It is intended as a reference for end-users. That section should be enough for end-users and every-day administration tasks.</description>
    </item>
    <item>
      <title>Virtual Routers</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/vrouter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/vrouter/</guid>
      <description>Virtual Routers provide routing across Virtual Networks. The administrators can easily connect Virtual Networks from Sunstone and the CLI. The routing itself is implemented with a Virtual Machine appliance available though the market place. This Virtual Machine can be seamlessly deployed in high availability mode.&#xA;Download the Virtual Router Appliance OpenNebula provides appliance which implements various Virtual Network Functions (VNFs), including the virtual router. The virtual router image is prepared to run in a HA mode, and process the context information from OpenNebula.</description>
    </item>
    <item>
      <title>VNF and Virtual Router</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/vnf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/vnf/</guid>
      <description>The VR in OpenNebula is a solution to common problems regarding management of VNETs and routing, including:&#xA;Keepalive Failover, High-Availability for the Service Virtual Router itself. Router4, to fine control routing between your virtual networks. NAT4, so you can enable your private virtual networks to reach the Internet. HAProxy Load Balancer, a robust layer4 (TCP) reverse-proxy/load-balancing solution. Keepalive LVS Load Balancer, so called layer4 switching, a high-performance load-balancing solution. SDNAT4, a public to private, private to public IP address mapping (SNAT + DNAT).</description>
    </item>
    <item>
      <title>Authentication Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-auth/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-auth/</guid>
      <description>This guide will show you how to develop a new driver for OpenNebula to interact with an external authentication service.&#xA;OpenNebula comes with an internal user/password way of authentication, this is called core. To be able to use other auth methods there is a system that performs authentication with external systems. Authentication drivers are responsible for getting the user credentials from OpenNebula database and login and answer whether the authentication is correct or not.</description>
    </item>
    <item>
      <title>Go OpenNebula Cloud API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/go/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/go/</guid>
      <description>This page contains the OpenNebula Cloud API Specification for Go. It has been designed as a wrapper for the XML-RPC methods, with some basic helpers. This means that you should be familiar with the XML-RPC API and the XML formats returned by the OpenNebula core. As stated in the XML-RPC documentation, you can download the XML Schemas (XSD) here.&#xA;Go OpenNebula Cloud API cover the resources lists below:&#xA;Resource URL ACL acl.</description>
    </item>
    <item>
      <title>Image States Reference</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/img_states/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/img_states/</guid>
      <description>This page is a complete reference of all the Image states that will be useful for administrators doing troubleshooting and developers.&#xA;The simplified life-cycle is explained in the Virtual Machines Images guide. That simplified diagram uses a smaller number of state names. That section should be enough for end-users and every-day administration tasks.&#xA;List of States OpenNebula’s images define its state using the STATE variable. The state can be seen from the CLI (oneimage show) and from Sunstone (Info panel for the Image).</description>
    </item>
    <item>
      <title>Known Issues</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/known_issues/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/known_issues/</guid>
      <description>A complete list of known issues for OpenNebula is maintained here.&#xA;This page will be updated with relevant information about bugs affecting OpenNebula, as well as possible workarounds until a patch is officially published.&#xA;Drivers - Virtualization libvirtd restarts in cycles each 10 minutes with error message in system logs, due to the way libvirtd gets activated per interaction by systemd in 120-second slices. As the default interval for the OpenNebula monitor probe is 600 seconds (10 minutes), each time a probe reactivates libvirtd, it sends those messages to syslog.</description>
    </item>
    <item>
      <title>minIO</title>
      <link>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/minio_intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/apps-marketplace/marketplace_appliances/minio_intro/</guid>
      <description>Placeholder text for new page based on the minIO wiki, https://github.com/OpenNebula/one-apps/wiki/minio_intro.</description>
    </item>
    <item>
      <title>NVIDIA GPU</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/vgpu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/hosts_and_clusters_configuration/vgpu/</guid>
      <description>This section describes how to configure the hypervisor in order to use NVIDIA vGPU features.&#xA;BIOS You need to check that the following settings are enabled in your BIOS configuration:&#xA;Enable SR-IOV Enable IOMMU Note that the specific menu options where you need to activate these features depends on the motherboard manufacturer.&#xA;NVIDIA Drivers The NVIDIA drivers are proprietary, so you will probably need to download them separately. Please check the documentation for your Linux distribution.</description>
    </item>
    <item>
      <title>OneFlow Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/oneflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/oneflow/</guid>
      <description>OneFlow orchestrates multi-VM services as a whole, interacts with the OpenNebula Daemon to manage the Virtual Machines (starts, stops), and can be controlled via the Sunstone GUI or over CLI. It’s a dedicated daemon installed by default as part of the Single Front-end Installation, but can be deployed independently on a different machine. The server is distributed as an operating system package opennebula-flow with the system service opennebula-flow.&#xA;Read more in Multi-VM Service Management.</description>
    </item>
    <item>
      <title>Permissions and ACLs</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/chmod/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/chmod/</guid>
      <description>Most OpenNebula resources have associated permissions for the owner, the users in her group, and others. For each one of these groups, there are three rights that can be set: USE, MANAGE and ADMIN. These permissions are very similar to those of UNIX file system.&#xA;The resources with associated permissions are Templates, VMs, Images and Virtual Networks. The exceptions are Users, Groups and Hosts.&#xA;Managing Permission through the CLI This is how the permissions look in the terminal:</description>
    </item>
    <item>
      <title>Restoring Previous Version</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/restoring_version/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/restoring_version/</guid>
      <description>&#xA;If for any reason you need to restore your previous OpenNebula, follow these steps:&#xA;With OpenNebula 7.0 still installed, restore the DB backup using onedb restore -f Uninstall OpenNebula 7.0, and install your previous version again. Copy back the backup of /etc/one you did to restore your configuration. </description>
    </item>
    <item>
      <title>Running Virtual Machines</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/running_virtual_machines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/running_virtual_machines/</guid>
      <description>In previous tutorials of this Quick Start Guide, we:&#xA;Installed an OpenNebula Front-end using miniONE, and Deployed a Metal Edge Cluster on AWS. In this tutorial, we’ll use that infrastructure to deploy a fully-configured virtual machine with a ready-to-use WordPress installation, in under five minutes.&#xA;We’ll follow these high-level steps:&#xA;Download the WordPress Appliance from the OpenNebula Marketplace. Instantiate the Virtual Machine for the Appliance. Verify the Installation by Connecting to WordPress.</description>
    </item>
    <item>
      <title>SAN Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/lvm_drivers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/lvm_drivers/</guid>
      <description>This storage configuration assumes that Hosts have access to storage devices (LUNs) exported by an Storage Area Network (SAN) server using a suitable protocol like iSCSI or Fiber Channel. The Hosts will interface the devices through the LVM abstraction layer. Virtual Machines run from a LV (logical volume) device instead of plain files. This reduces the overhead of having a filesystem in place and thus it may increase I/O performance.</description>
    </item>
    <item>
      <title>Transparent Proxies</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/tproxy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/virtual_machines_operation/virtual_machines_networking/tproxy/</guid>
      <description>Transparent Proxies make it possible to connect to management services, such as OneGate, by implicitly using the existing data center backbone networking. The OneGate service usually runs on the leader Front-end machine, which makes it difficult for Virtual Machines running in isolated virtual networks to contact it. This situation forces OpenNebula users to design virtual networking in advance, to ensure that VMs can securely reach OneGate. Transparent Proxies have been designed to remove that requirement.</description>
    </item>
    <item>
      <title>VXLAN Networks</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/vxlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/vxlan/</guid>
      <description>This guide describes how to enable Network isolation provided through the VXLAN encapsulation protocol. This driver will create a bridge for each OpenNebula Virtual Network and attach a VXLAN tagged network interface to the bridge.&#xA;The VXLAN ID will be the same for every interface in a given network, calculated automatically by OpenNebula. It may also be forced by setting the VLAN_ID attribute in the Virtual Network template.&#xA;Additionally, each VXLAN has an associated multicast address to encapsulate L2 broadcast and multicast traffic.</description>
    </item>
    <item>
      <title>Accounting</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/accounting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/accounting/</guid>
      <description>The accounting toolset visualizes and reports resource usage data. This accounting tool addresses the accounting of the virtual resources. It includes resource consumption of the virtual machines as reported from the hypervisor.&#xA;Usage oneacct - prints accounting information for virtual machines&#xA;Usage: oneacct [options] -s, --start TIME First day of the data to retrieve -e, --end TIME Last day of the data to retrieve -u, --userfilter user User name or id to filter the results -g, --group group Group name or id to filter the results -H, --host HOST Host name or id to filter the results --xpath XPATH_EXPRESSION Xpath expression to filter the results.</description>
    </item>
    <item>
      <title>Acknowledgements</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/release_notes/acknowledgements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/release_notes/acknowledgements/</guid>
      <description>The OpenNebula project would like to thank the community members and users who have contributed to this software release by being active in discussions, answering user questions, or providing patches for bugfixes, features, and documentation.&#xA;Some of the new functionality in OpenNebula 6.10 has been made possible through funding from the following innovation projects:&#xA;SovereignEdge.Cognit, funded by the European Union’s Horizon Europe research and innovation programme through the SovereignEdge.Cognit project: A Cognitive Serverless Framework for the Cloud-Edge Continuum (Grant Agreement 101092711 - SovereignEdge.</description>
    </item>
    <item>
      <title>Host States Reference</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/host_states/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/configuration_references/host_states/</guid>
      <description>This page is a complete reference of all the Host states that will be useful for administrators doing troubleshooting and developers.&#xA;The simplified life-cycle is explained in the Hosts guide. That simplified diagram uses a smaller number of state names. That section should be enough for end-users and every-day administration tasks.&#xA;List of States OpenNebula’s hosts define its state using the STATE variable. The state can be seen from the CLI (onehost show) and from Sunstone (Info panel for Hosts).</description>
    </item>
    <item>
      <title>Market Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-market/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-market/</guid>
      <description>The Market Driver is in charge of managing both Marketplaces and MarketPlace Apps.&#xA;Marketplace Drivers Structure The main drivers are located under /var/lib/one/remotes/market/&amp;lt;market_mad&amp;gt;. Marketplaces support the following operations:&#xA;Action Description create Create a new Marketplace. monitor This automatic action discovers the available Marketplace Apps andmonitors the available space of the Marketplace. delete Removes a Marketplace from OpenNebula. For a Public Marketplace,it will also remove the Marketplace Apps, but for any other type ofMarketplace this will not remove the Marketplace Apps, and willonly work if the Marketplace is empty.</description>
    </item>
    <item>
      <title>OneFlow Server API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/appflow_api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/appflow_api/</guid>
      <description>The OpenNebula OneFlow API is a RESTfull service to create, control and monitor services composed of interconnected Virtual Machines with deployment dependencies between them. Each group of Virtual Machines is deployed and managed as a single entity, and is completely integrated with the advanced OpenNebula user and group management. There are two kind of resources; services templates and services. All data is sent and received as JSON.&#xA;This guide is intended for developers.</description>
    </item>
    <item>
      <title>OneGate Configuration</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/onegate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/onegate/</guid>
      <description>The OneGate server allows Virtual Machines to pull and push information from/to OpenNebula. It can be used with all hypervisor Host types (KVM, LXC, and the legacy vCenter driver) if the guest operating system has preinstalled the OpenNebula contextualization package. It’s a dedicated daemon installed by default as part of the Single Front-end Installation, but can be deployed independently on a different machine. The server is distributed as an operating system package opennebula-gate with the system service opennebula-gate.</description>
    </item>
    <item>
      <title>Open vSwitch Networks</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/openvswitch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/networking_system_configuration/openvswitch/</guid>
      <description>This guide describes how to use the Open vSwitch network drivers. They provide network isolation using VLANs by tagging ports and basic network filtering using OpenFlow. Other traffic attributes that may be configured through Open vSwitch are not modified.&#xA;The VLAN ID will be the same for every interface in a given network, calculated automatically by OpenNebula. It may also be forced by specifying an VLAN_ID parameter in the Virtual Network template.</description>
    </item>
    <item>
      <title>Raw Device Mapping Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/dev_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/dev_ds/</guid>
      <description>The RDM Datastore is an Image Datastore that enables raw access to block devices on Nodes. This Datastore enables fast VM deployments due to a non-existent transfer operation from the Image Datastore to the System Datastore.&#xA;Warning The Datastore should only be usable by the administrators. Letting users create images in this Datastore is a huge security risk! For example, users could register an image /dev/sda and read the Host filesystem.</description>
    </item>
    <item>
      <title>Running Kubernetes Clusters</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/running_kubernetes_clusters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/running_kubernetes_clusters/</guid>
      <description>In previous tutorials of this Quick Start Guide, we:&#xA;Installed an OpenNebula Front-end using miniONE, deployed a Metal Edge Cluster on AWS, and deployed a Virtual Machine with WordPress on that Metal Edge Cluster. At this point, we are ready to deploy something more complex on our Metal Edge Cluster: an enterprise-grade, multi-master Kubernetes cluster based on SUSE Rancher’s RKE2 Kubernetes distribution. Like the WordPress VM, the Kubernetes cluster is available in the OpenNebula Public Marketplace.</description>
    </item>
    <item>
      <title>Upgrading from Previous Versions</title>
      <link>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrade_from_previous_versions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/releases/release_information/upgrade/upgrade_from_previous_versions/</guid>
      <description>If you need to upgrade from an OpenNebula version lower than 6.0, please contact your account manager at OpenNebula Systems, or alternatively open a ticket in the OpenNebula Systems support portal</description>
    </item>
    <item>
      <title>Database Maintenance</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/database/</guid>
      <description>OpenNebula persists the state of the cloud into the selected SQL database. The database should be monitored and tuned for the best performance by cloud administrators following the best practices of the particular database product. In this guide, we provide a few tips on how to optimize database for OpenNebula and thoroughly describe OpenNebula’s database maintenance tool onedb, which simplifies the most common database operations - backups and restores, version upgrades, or consistency checks.</description>
    </item>
    <item>
      <title>IPAM Driver</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-ipam/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/infrastructure_drivers_development/devel-ipam/</guid>
      <description>A IPAM driver lets you delegate IP lease management to an external component. This way you can coordinate IP use with other virtual or bare-metal servers in your datacenter. To effectively use an external IPAM you need to develop four action scripts that hooks on different points of the IP network/lease life-cycle.&#xA;Note that OpenNebula includes a built-in internal IPAM. You need to develop this component if you are using a IPAM server and want to coordinate OpenNebula with it.</description>
    </item>
    <item>
      <title>iSCSI - Libvirt Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/iscsi_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/iscsi_ds/</guid>
      <description>This Datastore is used to register already existing iSCSI volume available to the hypervisor Nodes.&#xA;Warning The Datastore should only be usable by the administrators. Letting users create images in this Datastore is a huge security risk! Front-end Setup No additional configuration is needed&#xA;Node Setup The Nodes need to meet the following requirements:&#xA;The devices you want to attach to a VM should be accessible by the hypervisor. QEMU needs to be compiled with libiscsi support.</description>
    </item>
    <item>
      <title>OneGate API</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/onegate_api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/onegate_api/</guid>
      <description>OneGate provides a REST API. To use this API you will need to get some data from the CONTEXT file. The contextualization cdrom should contain the context.sh and token.txt files.&#xA;# mkdir /mnt/context # mount /dev/hdb /mnt/context # cd /mnt/context # ls context.sh token.txt # cat context.sh # Context variables generated by OpenNebula DISK_ID=&amp;#39;1&amp;#39; ONEGATE_ENDPOINT=&amp;#39;http://192.168.0.1:5030&amp;#39; VMID=&amp;#39;0&amp;#39; TARGET=&amp;#39;hdb&amp;#39; TOKEN=&amp;#39;yes&amp;#39; # cat token.txt yCxieDUS7kra7Vn9ILA0+g== With that data, you can obtain the headers required for all the ONEGATE API methods:</description>
    </item>
    <item>
      <title>Operating an Edge Cluster</title>
      <link>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/operating_edge_cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_installation/try_opennebula_with_minione/quick_start_opennebula_evaluation_environment/operating_edge_cluster/</guid>
      <description>In Provisioning an Edge Cluster, we used the OneProvision GUI to create an Edge Cluster in AWS.&#xA;This page provides an overview of all resources created in OpenNebula during that deployment, which together comprise the Edge Cluster.&#xA;All resources in the Edge Cluster are created from templates. Templates contain all of the information for the physical features of resources. For some templates, such as the network templates, users need to provide the logical attributes at the moment of instantiating the template, such as the IP or the address range.</description>
    </item>
    <item>
      <title>Showback</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/showback/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_system_administration/multitenancy/showback/</guid>
      <description>The showback toolset reports resource usage cost, and allows the integration with chargeback and billing platforms. The toolset generates showback reports using the information retrieved from OpenNebula.&#xA;Set the VM Cost Each VM Template can optionally define a cost (see the syntax here). The cost is defined as cost per cpu per hour, and cost per memory MB per hour. The cost units are abstract and their equivalent to monetary or other cost metrics have to be defined in each deployment.</description>
    </item>
    <item>
      <title>Kernels and Files Datastore</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/file_ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/storage_system_configuration/file_ds/</guid>
      <description>The Kernels &amp;amp; Files Datastore lets you store plain files to be used as VM kernels, ramdisks or any other files that need to be passed to the VM through the contextualization process. The Kernels &amp;amp; Files Datastore does not expose any special storage mechanism but is a simple and secure way to use files within VM templates.&#xA;Configuration The datastores common configuration attributes apply to the Kernels &amp;amp; Files Datastores and can be defined during the creation process or updated once the datastore have been created.</description>
    </item>
    <item>
      <title>Troubleshooting</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/troubleshooting/</guid>
      <description>Logging Every OpenNebula server generates logs with a configurable verbosity (level of detail) and through different means (file, syslog, or standard error output) to allow cloud administrators to troubleshoot the potential problems. Logs are stored in /var/log/one/ on a Front-end Host with a particular component. Some valuable error messages can be also seen by the end-users in CLI tools or the Sunstone GUI.&#xA;Configure Logging System Follow the guides of each component to find the logs’ location and configuration of log verbosity:</description>
    </item>
    <item>
      <title>Using Hooks</title>
      <link>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/hook_driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/integration_framework/integration_references/system_interfaces/hook_driver/</guid>
      <description>The Hook subsystem enables the execution of custom scripts tied to a change in state in a particular resource, or API call. This opens a wide area of automation for system administrators to tailor their cloud infrastructures. It also features a logging mechanism that allows a convenient way to query the execution history or to retry the execution of a given hook.&#xA;Overview The hook subsystem has two main components:</description>
    </item>
    <item>
      <title>Replace failing frontend</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/replace_failing_fe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/replace_failing_fe/</guid>
      <description>Follow this guide as the oneadmin user. To switch the user run:&#xA;sudo -i -u oneadmin Back up files This command has to be executed in the failing host.&#xA;Create the backup directory:&#xA;BAK_DIR=~/one_backup mkdir -p $BAK_DIR Copy configuration directory /etc/one to backup directory:&#xA;cp -rp --parents /etc/one $BAK_DIR Copy remotes directory /var/lib/one/remotes to backup directory:&#xA;cp -rp --parents /var/lib/one/remotes $BAK_DIR Copy keys directory /var/lib/one/.one to backup directory:&#xA;cp -rp --parents /var/lib/one/.</description>
    </item>
    <item>
      <title>Support Utilities (EE)</title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/operation_references/opennebula_services_configuration/support/</guid>
      <description>OpenNebula provides customers with means to generate diagnostic bundles with all details necessary to handle the support cases. There are two specialized tools contained in the OpenNebula server package for this purpose:&#xA;OneGather: Generates an archive bundle with information about the OpenNebula instance, like configuration, database and hosts state. OneSupport: Only for vCenter deployments, on top of bundles, it also allows to scan permissions used to interact with the vCenter cluster.</description>
    </item>
    <item>
      <title></title>
      <link>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/io_limit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://opennebula.github.io/website/docs/cloud_operation/cloud_clusters_infrastructure_configuration/backup_system_configuration/io_limit/</guid>
      <description>Backup operations may incur in a high I/O or CPU demands. This will add noise to the VMs running in the hypervisor. You can control resource usage of the backup operations by:&#xA;Lower the priority of the associated processes. Backup commands are run under a given ionice priority (best-effort, class 2 scheduler); and a given nice. Confine the associated processes in a cgroup. OpenNebula will create a systemd slice for each backup datastore so the backup commands run with a limited number or read/write IOPS and CPU Quota.</description>
    </item>
  </channel>
</rss>
