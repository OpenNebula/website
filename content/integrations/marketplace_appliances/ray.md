---
title: "Ray AI"
date: "2025-02-17"
description:
categories:
pageintoc: "200"
tags:
weight: "25"
---

<a id="ray-intro"></a>

<!--# minIO -->

## Appliance Description

[Ray](https://www.ray.io/) is an open-source framework for distributed computing and machine learning workloads. The [Ray appliance](https://github.com/OpenNebula/one-apps/wiki/ray_intro) leveragles Ray's **Serve** library to enable efficient deployment of inference APIs, and includes the [vLLM](https://docs.vllm.ai/en/latest/) for fast inference and serving.

## Main Features

The Ray appliance includes two frameworks for running LLMs:

- [Hugging Face - Transformers](https://huggingface.co/docs/transformers/index), one of the most widely adopted frameworks for deploying large language models
- vLLM, the open source, high-perfomance engine for serving large language models with low latency and high throughput
- Configurable deployment options and behavior, controlled by contextualization parameters

## Main References

- [Ray](https://github.com/OpenNebula/one-apps/tree/master/appliances/Ray) in the [OpenNebula one-apps](https://github.com/OpenNebula/one-apps) project
- [Full documentation](https://github.com/OpenNebula/one-apps/wiki/ray_intro) for the Ray appliance
- Download the Ray appliance from the [OpenNebula Marketplace](https://marketplace.opennebula.io/appliance/04132560-bebf-013d-a767-7875a4a4f528)
